{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisjmccormick/shared-subspaces/blob/main/subspace_decoder/scripts/run_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ip42SV3Jr39"
      },
      "source": [
        "# â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-A4hvT3JsjL"
      },
      "source": [
        "# Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5SFQDjNJtk2"
      },
      "source": [
        "This notebook demonstrates how to run the pre-training and fine-tuning scripts from a command line, and is also setup to allow you to run then from within the notebook.\n",
        "\n",
        "**Running on Colab**\n",
        "\n",
        "The current configurations require the 40GB A100 because of the pre-training batch size.\n",
        "\n",
        "(If you wanted to run on a T4, you could adjust the training arguments to use batch accumulation. This would allow you to preserve the training behavior without running out of memory.)\n",
        "\n",
        "What to expect:\n",
        "\n",
        "* Pre-training runs take roughly 75 minutes. It's pushing the limit of what works well in Colab--you'll want to babysit the notebook a little to avoid disconnect issues.\n",
        "\n",
        "* Fine-tuning is relatively fast, and completes in under 10 minutes.\n",
        "\n",
        "**Training Arguments**\n",
        "\n",
        "I designed the scripts such that everything is specified through `.json` config files rather than on the command line. However, there is a command line utility to define new configurations--see the \"Defining a New Run\" section at the end of this notebook.\n",
        "\n",
        "The examples below run one of the existing configurations.\n",
        "\n",
        "**Weights and Biases**\n",
        "\n",
        "The scripts are set up to log to wandb by default. You can change the `wandb_mode` variable below to 'offline' if you don't have an account / don't want to log online.\n",
        "\n",
        "The project names are currently hardcoded to:\n",
        "\n",
        "* Pretraining: `decoder-pretrain-wiki103`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA-wKp3rYTB5"
      },
      "source": [
        "# â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyegsMa3mLhA"
      },
      "source": [
        "# S1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fmU5PmGGjYa"
      },
      "source": [
        "## 1.1. Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg9vyvjEYD3D"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/chrisjmccormick/shared-subspaces.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcmcny0IjIl3"
      },
      "source": [
        "Provide the full path to the subspace_decoder folder.\n",
        "\n",
        "This will be added to the PYTHONPATH when executing the scripts so that they can import the classes from the local files.\n",
        "\n",
        "This variable is also used to construct paths to config files and scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em7Cu-VrjFRa"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/shared-subspaces/subspace_decoder\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4sOT95lInOc"
      },
      "source": [
        "## 1.2. Weights & Biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfjqf9ynkjkq"
      },
      "source": [
        "To provide your wandb API key for the script:\n",
        "1. You could paste it in manually on the training command lines further down.\n",
        "2. Or, use the secrets panel (the key symbol on the left edge of the notebook) and:\n",
        "    * Define your wandb api key as `wandb_api_key`.\n",
        "    * Grant access to this notebook.\n",
        "    * Run the below cell to retrieve it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4mf-KNWjEVZ"
      },
      "outputs": [],
      "source": [
        "# Get key from colab secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set to false if you don't want to use wandb.\n",
        "# The scripts will still log using the wandb library, but to a local directory.\n",
        "use_wandb = True\n",
        "\n",
        "if use_wandb:\n",
        "    # Enable Weights & Biases logging (online mode)\n",
        "    wandb_mode = \"online\"\n",
        "\n",
        "    # Get wandb API key from Colab secrets\n",
        "    wandb_key = userdata.get(\"wandb_api_key\")\n",
        "\n",
        "# Set to offline if you don't want to log in.\n",
        "else:\n",
        "    wandb_mode = \"offline\"\n",
        "\n",
        "    wandb_key = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6UjLucskFCQ"
      },
      "source": [
        "## 1.3. Choose Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6Sp7iLw7wQ-",
        "outputId": "6a74899d-2474-4103-b74d-4fa3bf83f705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== /content/shared-subspaces/subspace_encoder/configs/mha_rope_baseline.json ========\n",
            "\n",
            "{\n",
            "    \"shorthand\": \"rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32\",\n",
            "    \"notes\": \"Baseline using standard MHA with RoPE\",\n",
            "    \"model\": {\n",
            "        \"hidden_size\": 256,\n",
            "        \"num_hidden_layers\": 6,\n",
            "        \"intermediate_size\": 1024,\n",
            "        \"hidden_dropout_prob\": 0.1,\n",
            "        \"attention_dropout_prob\": 0.1,\n",
            "        \"classifier_dropout\": null,\n",
            "        \"initializer_range\": 0.02,\n",
            "        \"layer_norm_eps\": 1e-12,\n",
            "        \"rms_norm_eps\": 1e-06,\n",
            "        \"vocab_size\": 30522,\n",
            "        \"rope_theta\": 10000.0,\n",
            "        \"rope_scaling\": null,\n",
            "        \"max_position_embeddings\": 128,\n",
            "        \"num_dense_layers\": 6,\n",
            "        \"q_latent_dim\": null,\n",
            "        \"kv_latent_dim\": null,\n",
            "        \"num_attention_heads\": 8,\n",
            "        \"head_dim\": 32,\n",
            "        \"rope_dims\": 32,\n",
            "        \"attention_bias\": false,\n",
            "        \"output_subspace\": false,\n",
            "        \"o_latent_dim\": null,\n",
            "        \"attention_backend\": \"sdpa\",\n",
            "        \"ffn_decompose\": false,\n",
            "        \"ffn_rank\": null,\n",
            "        \"vocab_subspace\": false,\n",
            "        \"vocab_rank\": null\n",
            "    },\n",
            "    \"pre_train\": {\n",
            "        \"output_dir\": \"checkpoints/mha_rope_baseline\",\n",
            "        \"seed\": 42,\n",
            "        \"train_batch_size\": 256,\n",
            "        \"learning_rate\": 0.0005,\n",
            "        \"num_train_steps\": 50000,\n",
            "        \"eval_steps\": 2000,\n",
            "        \"weight_decay\": 0.01,\n",
            "        \"mlm_probability\": 0.15,\n",
            "        \"dataset_name\": \"wikitext\",\n",
            "        \"dataset_config\": \"wikitext-103-raw-v1\",\n",
            "        \"max_seq_length\": 128,\n",
            "        \"eval_batch_size\": 64,\n",
            "        \"fp16\": true\n",
            "    },\n",
            "    \"fine_tune\": {\n",
            "        \"task\": \"sst2\",\n",
            "        \"batch_size\": 16,\n",
            "        \"lr\": 2e-05,\n",
            "        \"epochs\": 3,\n",
            "        \"seed\": 42,\n",
            "        \"max_length\": 128,\n",
            "        \"weight_decay\": 0,\n",
            "        \"warmup_ratio\": 0\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "#  Choose which config file to run\n",
        "pretrain_config_path = f\"{base_path}/configs/initial_mla.json\"\n",
        "#pretrain_config_path = f\"{base_path}/configs/best_mla-o.json\"\n",
        "\n",
        "# Make sure it's a valid path\n",
        "if not os.path.exists(pretrain_config_path):\n",
        "    raise ValueError(f\"Config file {pretrain_config_path} does not exist.\")\n",
        "\n",
        "# Print it out.\n",
        "with open(pretrain_config_path, \"r\") as f:\n",
        "    pretrain_config = json.load(f)\n",
        "\n",
        "print(f\"\\n======== {pretrain_config_path} ========\\n\")\n",
        "\n",
        "# Print out the configuration with spacing.\n",
        "json_str = json.dumps(pretrain_config, indent=4)\n",
        "print(json_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVSazfr1kGw_"
      },
      "source": [
        "# S2. Run Pre-Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_09o6vrPir9K",
        "outputId": "ae351686-7163-4d17-9318-86fb1cde7ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======= Pre-Train ========\n",
            "\n",
            "Importing Packages...\n",
            "\n",
            "2025-08-08 15:28:26.969088: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-08 15:28:26.987237: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1754666907.008364    4512 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1754666907.014845    4512 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1754666907.031469    4512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754666907.031499    4512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754666907.031502    4512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1754666907.031505    4512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-08 15:28:27.036316: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "PROJECT_ROOT /content/shared-subspaces/subspace_encoder\n",
            "rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrismccormick\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 1801350\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n",
            "Map (num_proc=8): 100% 4358/4358 [00:00<00:00, 7342.57 examples/s] \n",
            "Map (num_proc=8): 100% 1801350/1801350 [01:16<00:00, 23474.37 examples/s]\n",
            "Map (num_proc=8): 100% 3760/3760 [00:00<00:00, 7638.24 examples/s]\n",
            "SharedSpaceEncoderForMaskedLM(\n",
            "  (encoder_model): SharedSpaceEncoderModel(\n",
            "    (vocab_embed): Embedding(30522, 256)\n",
            "    (rope): RotaryEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0-5): 6 x SharedSpaceEncoderLayer(\n",
            "        (attn_input_norm): DeepseekV3RMSNorm()\n",
            "        (self_attn): MultiheadLatentAttention(\n",
            "          (qkv_proj): Linear(in_features=256, out_features=768, bias=False)\n",
            "          (o_proj): Linear(in_features=256, out_features=256, bias=False)\n",
            "        )\n",
            "        (ffn_input_norm): DeepseekV3RMSNorm()\n",
            "        (ffn): SubspaceFeedForward(\n",
            "          (W_in): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (W_gate): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (W_out): Linear(in_features=1024, out_features=256, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "======== Model ========\n",
            "\n",
            "======== Pre-Train ========\n",
            "{\n",
            "  \"output_dir\": \"checkpoints/mha_rope_baseline\",\n",
            "  \"seed\": 42,\n",
            "  \"train_batch_size\": 256,\n",
            "  \"learning_rate\": 0.0005,\n",
            "  \"num_train_steps\": 50000,\n",
            "  \"eval_steps\": 2000,\n",
            "  \"weight_decay\": 0.01,\n",
            "  \"mlm_probability\": 0.15,\n",
            "  \"dataset_name\": \"wikitext\",\n",
            "  \"dataset_config\": \"wikitext-103-raw-v1\",\n",
            "  \"max_seq_length\": 128,\n",
            "  \"eval_batch_size\": 64,\n",
            "  \"fp16\": true\n",
            "}\n",
            "=============================\n",
            "\n",
            "\n",
            "======== Parameters ========\n",
            "The model has 61 different named parameters.\n",
            "\n",
            "Total elements: 13.47M\n",
            "\n",
            "The model has 61 different named parameters.\n",
            "\n",
            "Total elements: 13.47M\n",
            "\n",
            "Parameter Name                                              Dimensions       Total Values    Trainable\n",
            "\n",
            "encoder_model.vocab_embed.weight                            30,522 x 256            7.45M    True\n",
            "encoder_model.layers.0.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.0.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.0.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.0.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.0.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.0.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.0.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.0.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.0.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.0.ffn.W_out.bias                          256 x -               256     True\n",
            "encoder_model.layers.1.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.1.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.1.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.1.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.1.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.1.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.1.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.1.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.1.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.1.ffn.W_out.bias                          256 x -               256     True\n",
            "encoder_model.layers.2.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.2.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.2.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.2.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.2.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.2.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.2.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.2.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.2.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.2.ffn.W_out.bias                          256 x -               256     True\n",
            "encoder_model.layers.3.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.3.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.3.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.3.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.3.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.3.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.3.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.3.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.3.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.3.ffn.W_out.bias                          256 x -               256     True\n",
            "encoder_model.layers.4.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.4.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.4.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.4.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.4.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.4.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.4.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.4.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.4.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.4.ffn.W_out.bias                          256 x -               256     True\n",
            "encoder_model.layers.5.attn_input_norm.weight                  256 x -               256     True\n",
            "encoder_model.layers.5.self_attn.qkv_proj.weight               768 x 256             192K    True\n",
            "encoder_model.layers.5.self_attn.o_proj.weight                 256 x 256              64K    True\n",
            "encoder_model.layers.5.ffn_input_norm.weight                   256 x -               256     True\n",
            "encoder_model.layers.5.ffn.W_in.weight                       1,024 x 256             256K    True\n",
            "encoder_model.layers.5.ffn.W_in.bias                         1,024 x -                 1K    True\n",
            "encoder_model.layers.5.ffn.W_gate.weight                     1,024 x 256             256K    True\n",
            "encoder_model.layers.5.ffn.W_gate.bias                       1,024 x -                 1K    True\n",
            "encoder_model.layers.5.ffn.W_out.weight                        256 x 1,024           256K    True\n",
            "encoder_model.layers.5.ffn.W_out.bias                          256 x -               256     True\n",
            "\n",
            "Total elements: 13.47M\n",
            "\n",
            "13.47M - rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250808_152951-v5b5e3gh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m13.47M - rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/chrismccormick/encoder-pretrain-wiki103\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/chrismccormick/encoder-pretrain-wiki103/runs/v5b5e3gh\u001b[0m\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=True,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=8,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=2000,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0005,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=checkpoints/mha_rope_baseline/runs/Aug08_15-29-52_5608ebbc9614,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=50,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=50000,\n",
            "metric_for_best_model=eval_accuracy,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=checkpoints/mha_rope_baseline,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=64,\n",
            "per_device_train_batch_size=256,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=13.47M - rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=2000,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=2,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=5000,\n",
            "weight_decay=0.01,\n",
            ")\n",
            "{'loss': 10.2864, 'grad_norm': 0.8547677993774414, 'learning_rate': 4.9e-06, 'epoch': 0.01}\n",
            "{'loss': 10.1157, 'grad_norm': 1.2550615072250366, 'learning_rate': 9.900000000000002e-06, 'epoch': 0.01}\n",
            "{'loss': 9.6547, 'grad_norm': 2.6960854530334473, 'learning_rate': 1.49e-05, 'epoch': 0.02}\n",
            "{'loss': 8.558, 'grad_norm': 2.8615670204162598, 'learning_rate': 1.9900000000000003e-05, 'epoch': 0.03}\n",
            "{'loss': 7.5958, 'grad_norm': 1.5296196937561035, 'learning_rate': 2.49e-05, 'epoch': 0.04}\n",
            "{'loss': 7.2722, 'grad_norm': 1.607062816619873, 'learning_rate': 2.9900000000000002e-05, 'epoch': 0.04}\n",
            "{'loss': 7.1933, 'grad_norm': 1.5905518531799316, 'learning_rate': 3.49e-05, 'epoch': 0.05}\n",
            "{'loss': 7.1794, 'grad_norm': 1.7226825952529907, 'learning_rate': 3.99e-05, 'epoch': 0.06}\n",
            "{'loss': 7.1423, 'grad_norm': 1.9286644458770752, 'learning_rate': 4.49e-05, 'epoch': 0.06}\n",
            "{'loss': 7.1067, 'grad_norm': 1.4219807386398315, 'learning_rate': 4.99e-05, 'epoch': 0.07}\n",
            "{'loss': 7.0315, 'grad_norm': 1.8703397512435913, 'learning_rate': 5.49e-05, 'epoch': 0.08}\n",
            "{'loss': 6.9756, 'grad_norm': 1.9404735565185547, 'learning_rate': 5.9900000000000006e-05, 'epoch': 0.09}\n",
            "{'loss': 6.8857, 'grad_norm': 2.1070640087127686, 'learning_rate': 6.49e-05, 'epoch': 0.09}\n",
            "{'loss': 6.7373, 'grad_norm': 1.685856580734253, 'learning_rate': 6.99e-05, 'epoch': 0.1}\n",
            "{'loss': 6.6291, 'grad_norm': 2.2474617958068848, 'learning_rate': 7.489999999999999e-05, 'epoch': 0.11}\n",
            "{'loss': 6.5259, 'grad_norm': 2.3754122257232666, 'learning_rate': 7.99e-05, 'epoch': 0.11}\n",
            "{'loss': 6.4416, 'grad_norm': 2.284954071044922, 'learning_rate': 8.49e-05, 'epoch': 0.12}\n",
            "{'loss': 6.3275, 'grad_norm': 2.896345376968384, 'learning_rate': 8.989999999999999e-05, 'epoch': 0.13}\n",
            "{'loss': 6.2548, 'grad_norm': 2.756645441055298, 'learning_rate': 9.49e-05, 'epoch': 0.14}\n",
            "{'loss': 6.1443, 'grad_norm': 2.3669989109039307, 'learning_rate': 9.99e-05, 'epoch': 0.14}\n",
            "{'loss': 6.0759, 'grad_norm': 2.739164113998413, 'learning_rate': 0.0001049, 'epoch': 0.15}\n",
            "{'loss': 5.9874, 'grad_norm': 3.0774569511413574, 'learning_rate': 0.0001099, 'epoch': 0.16}\n",
            "{'loss': 5.8935, 'grad_norm': 3.1050612926483154, 'learning_rate': 0.0001149, 'epoch': 0.16}\n",
            "{'loss': 5.8097, 'grad_norm': 2.502619504928589, 'learning_rate': 0.00011990000000000001, 'epoch': 0.17}\n",
            "{'loss': 5.7562, 'grad_norm': 3.044396162033081, 'learning_rate': 0.0001249, 'epoch': 0.18}\n",
            "{'loss': 5.6857, 'grad_norm': 3.285085678100586, 'learning_rate': 0.00012989999999999999, 'epoch': 0.18}\n",
            "{'loss': 5.6427, 'grad_norm': 3.1234757900238037, 'learning_rate': 0.0001349, 'epoch': 0.19}\n",
            "{'loss': 5.5446, 'grad_norm': 3.12597393989563, 'learning_rate': 0.0001399, 'epoch': 0.2}\n",
            "{'loss': 5.5235, 'grad_norm': 3.00134539604187, 'learning_rate': 0.0001449, 'epoch': 0.21}\n",
            "{'loss': 5.4392, 'grad_norm': 2.8071863651275635, 'learning_rate': 0.0001499, 'epoch': 0.21}\n",
            "{'loss': 5.4054, 'grad_norm': 2.8577630519866943, 'learning_rate': 0.00015490000000000002, 'epoch': 0.22}\n",
            "{'loss': 5.3615, 'grad_norm': 2.785449981689453, 'learning_rate': 0.00015989999999999998, 'epoch': 0.23}\n",
            "{'loss': 5.3135, 'grad_norm': 3.309685468673706, 'learning_rate': 0.0001649, 'epoch': 0.23}\n",
            "{'loss': 5.2748, 'grad_norm': 2.6688590049743652, 'learning_rate': 0.0001699, 'epoch': 0.24}\n",
            "{'loss': 5.2305, 'grad_norm': 3.1154048442840576, 'learning_rate': 0.0001749, 'epoch': 0.25}\n",
            "{'loss': 5.1977, 'grad_norm': 3.0179264545440674, 'learning_rate': 0.0001799, 'epoch': 0.26}\n",
            "{'loss': 5.1583, 'grad_norm': 3.572021961212158, 'learning_rate': 0.00018490000000000002, 'epoch': 0.26}\n",
            "{'loss': 5.1307, 'grad_norm': 3.606934070587158, 'learning_rate': 0.0001899, 'epoch': 0.27}\n",
            "{'loss': 5.075, 'grad_norm': 2.740159034729004, 'learning_rate': 0.0001949, 'epoch': 0.28}\n",
            "{'loss': 5.0592, 'grad_norm': 2.8089048862457275, 'learning_rate': 0.0001999, 'epoch': 0.28}\n",
            "  4% 2000/50000 [03:03<1:12:22, 11.05it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/59 [00:00<00:04, 14.19it/s]\u001b[A\n",
            " 12% 7/59 [00:00<00:01, 29.68it/s]\u001b[A\n",
            " 20% 12/59 [00:00<00:01, 35.42it/s]\u001b[A\n",
            " 29% 17/59 [00:00<00:01, 37.94it/s]\u001b[A\n",
            " 36% 21/59 [00:00<00:01, 30.36it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 25.05it/s]\u001b[A\n",
            " 47% 28/59 [00:01<00:01, 21.82it/s]\u001b[A\n",
            " 53% 31/59 [00:01<00:01, 20.68it/s]\u001b[A\n",
            " 58% 34/59 [00:01<00:01, 19.96it/s]\u001b[A\n",
            " 63% 37/59 [00:01<00:01, 20.48it/s]\u001b[A\n",
            " 68% 40/59 [00:01<00:00, 20.91it/s]\u001b[A\n",
            " 73% 43/59 [00:01<00:00, 19.00it/s]\u001b[A\n",
            " 76% 45/59 [00:01<00:00, 18.81it/s]\u001b[A\n",
            " 80% 47/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 83% 49/59 [00:02<00:00, 18.53it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.48it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.45it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.42it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.953641414642334, 'eval_accuracy': 0.31402403116226196, 'eval_runtime': 3.0704, 'eval_samples_per_second': 1224.604, 'eval_steps_per_second': 19.216, 'epoch': 0.28}\n",
            "  4% 2000/50000 [03:06<1:12:22, 11.05it/s]\n",
            "100% 59/59 [00:02<00:00, 19.64it/s]\u001b[A\n",
            "{'loss': 5.0358, 'grad_norm': 2.829078435897827, 'learning_rate': 0.0002049, 'epoch': 0.29}\n",
            "{'loss': 4.965, 'grad_norm': 2.6394495964050293, 'learning_rate': 0.0002099, 'epoch': 0.3}\n",
            "{'loss': 4.9481, 'grad_norm': 2.672199010848999, 'learning_rate': 0.00021490000000000002, 'epoch': 0.31}\n",
            "{'loss': 4.9329, 'grad_norm': 2.7892701625823975, 'learning_rate': 0.0002199, 'epoch': 0.31}\n",
            "{'loss': 4.8849, 'grad_norm': 2.6027863025665283, 'learning_rate': 0.0002249, 'epoch': 0.32}\n",
            "{'loss': 4.8623, 'grad_norm': 2.8807389736175537, 'learning_rate': 0.0002299, 'epoch': 0.33}\n",
            "{'loss': 4.8706, 'grad_norm': 2.4997992515563965, 'learning_rate': 0.0002349, 'epoch': 0.33}\n",
            "{'loss': 4.8575, 'grad_norm': 2.574115753173828, 'learning_rate': 0.0002399, 'epoch': 0.34}\n",
            "{'loss': 4.7802, 'grad_norm': 2.693070650100708, 'learning_rate': 0.0002449, 'epoch': 0.35}\n",
            "{'loss': 4.7732, 'grad_norm': 2.712951421737671, 'learning_rate': 0.0002499, 'epoch': 0.36}\n",
            "{'loss': 4.7539, 'grad_norm': 2.4879496097564697, 'learning_rate': 0.0002549, 'epoch': 0.36}\n",
            "{'loss': 4.7459, 'grad_norm': 2.476165533065796, 'learning_rate': 0.00025990000000000003, 'epoch': 0.37}\n",
            "{'loss': 4.7037, 'grad_norm': 2.7336370944976807, 'learning_rate': 0.00026490000000000004, 'epoch': 0.38}\n",
            "{'loss': 4.6689, 'grad_norm': 2.626868724822998, 'learning_rate': 0.0002699, 'epoch': 0.38}\n",
            "{'loss': 4.6651, 'grad_norm': 2.6280136108398438, 'learning_rate': 0.00027489999999999996, 'epoch': 0.39}\n",
            "{'loss': 4.6361, 'grad_norm': 2.453939437866211, 'learning_rate': 0.0002799, 'epoch': 0.4}\n",
            "{'loss': 4.6302, 'grad_norm': 2.2461931705474854, 'learning_rate': 0.0002849, 'epoch': 0.41}\n",
            "{'loss': 4.5987, 'grad_norm': 2.4633681774139404, 'learning_rate': 0.0002899, 'epoch': 0.41}\n",
            "{'loss': 4.591, 'grad_norm': 2.4191524982452393, 'learning_rate': 0.0002949, 'epoch': 0.42}\n",
            "{'loss': 4.5719, 'grad_norm': 2.411076545715332, 'learning_rate': 0.0002999, 'epoch': 0.43}\n",
            "{'loss': 4.5663, 'grad_norm': 2.2698426246643066, 'learning_rate': 0.0003049, 'epoch': 0.43}\n",
            "{'loss': 4.531, 'grad_norm': 2.2996301651000977, 'learning_rate': 0.0003099, 'epoch': 0.44}\n",
            "{'loss': 4.5221, 'grad_norm': 2.319819450378418, 'learning_rate': 0.0003149, 'epoch': 0.45}\n",
            "{'loss': 4.4845, 'grad_norm': 2.305657148361206, 'learning_rate': 0.0003199, 'epoch': 0.45}\n",
            "{'loss': 4.4789, 'grad_norm': 2.488142967224121, 'learning_rate': 0.00032490000000000004, 'epoch': 0.46}\n",
            "{'loss': 4.4316, 'grad_norm': 2.4393718242645264, 'learning_rate': 0.00032990000000000005, 'epoch': 0.47}\n",
            "{'loss': 4.4279, 'grad_norm': 2.2719032764434814, 'learning_rate': 0.0003349, 'epoch': 0.48}\n",
            "{'loss': 4.4164, 'grad_norm': 2.1935107707977295, 'learning_rate': 0.00033989999999999997, 'epoch': 0.48}\n",
            "{'loss': 4.4066, 'grad_norm': 2.286604166030884, 'learning_rate': 0.0003449, 'epoch': 0.49}\n",
            "{'loss': 4.4111, 'grad_norm': 2.35125470161438, 'learning_rate': 0.0003499, 'epoch': 0.5}\n",
            "{'loss': 4.3571, 'grad_norm': 2.126532554626465, 'learning_rate': 0.0003549, 'epoch': 0.5}\n",
            "{'loss': 4.3724, 'grad_norm': 2.1405086517333984, 'learning_rate': 0.0003599, 'epoch': 0.51}\n",
            "{'loss': 4.345, 'grad_norm': 2.124535322189331, 'learning_rate': 0.00036490000000000003, 'epoch': 0.52}\n",
            "{'loss': 4.3144, 'grad_norm': 2.165095567703247, 'learning_rate': 0.0003699, 'epoch': 0.53}\n",
            "{'loss': 4.2935, 'grad_norm': 2.0715529918670654, 'learning_rate': 0.0003749, 'epoch': 0.53}\n",
            "{'loss': 4.2987, 'grad_norm': 2.205880880355835, 'learning_rate': 0.0003799, 'epoch': 0.54}\n",
            "{'loss': 4.2899, 'grad_norm': 2.2010836601257324, 'learning_rate': 0.00038490000000000003, 'epoch': 0.55}\n",
            "{'loss': 4.269, 'grad_norm': 2.194950819015503, 'learning_rate': 0.00038990000000000004, 'epoch': 0.55}\n",
            "{'loss': 4.24, 'grad_norm': 2.324636697769165, 'learning_rate': 0.0003949, 'epoch': 0.56}\n",
            "{'loss': 4.2277, 'grad_norm': 2.320976734161377, 'learning_rate': 0.00039989999999999996, 'epoch': 0.57}\n",
            "  8% 4000/50000 [06:07<1:09:09, 11.09it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.88it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 42.65it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 42.90it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.93it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 30.41it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.87it/s]\u001b[A\n",
            " 56% 33/59 [00:01<00:01, 23.56it/s]\u001b[A\n",
            " 61% 36/59 [00:01<00:01, 22.08it/s]\u001b[A\n",
            " 66% 39/59 [00:01<00:00, 20.93it/s]\u001b[A\n",
            " 71% 42/59 [00:01<00:00, 20.19it/s]\u001b[A\n",
            " 76% 45/59 [00:01<00:00, 19.66it/s]\u001b[A\n",
            " 81% 48/59 [00:01<00:00, 19.18it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 19.04it/s]\u001b[A\n",
            " 88% 52/59 [00:02<00:00, 18.83it/s]\u001b[A\n",
            " 92% 54/59 [00:02<00:00, 18.71it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.57it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.080517768859863, 'eval_accuracy': 0.38162529468536377, 'eval_runtime': 2.8681, 'eval_samples_per_second': 1310.951, 'eval_steps_per_second': 20.571, 'epoch': 0.57}\n",
            "  8% 4000/50000 [06:10<1:09:09, 11.09it/s]\n",
            "100% 59/59 [00:02<00:00, 18.42it/s]\u001b[A\n",
            "{'loss': 4.2259, 'grad_norm': 2.1667284965515137, 'learning_rate': 0.0004049, 'epoch': 0.58}\n",
            "{'loss': 4.1828, 'grad_norm': 1.9937375783920288, 'learning_rate': 0.0004099, 'epoch': 0.58}\n",
            "{'loss': 4.1977, 'grad_norm': 2.057219982147217, 'learning_rate': 0.0004149, 'epoch': 0.59}\n",
            "{'loss': 4.1857, 'grad_norm': 2.0581626892089844, 'learning_rate': 0.0004199, 'epoch': 0.6}\n",
            "{'loss': 4.1574, 'grad_norm': 1.9805465936660767, 'learning_rate': 0.00042490000000000003, 'epoch': 0.6}\n",
            "{'loss': 4.1434, 'grad_norm': 1.9441032409667969, 'learning_rate': 0.0004299, 'epoch': 0.61}\n",
            "{'loss': 4.1158, 'grad_norm': 1.9764243364334106, 'learning_rate': 0.0004349, 'epoch': 0.62}\n",
            "{'loss': 4.0766, 'grad_norm': 2.002467393875122, 'learning_rate': 0.0004399, 'epoch': 0.63}\n",
            "{'loss': 4.0726, 'grad_norm': 2.0349392890930176, 'learning_rate': 0.0004449, 'epoch': 0.63}\n",
            "{'loss': 4.0735, 'grad_norm': 2.116716146469116, 'learning_rate': 0.00044990000000000004, 'epoch': 0.64}\n",
            "{'loss': 4.0165, 'grad_norm': 1.9645181894302368, 'learning_rate': 0.00045490000000000005, 'epoch': 0.65}\n",
            "{'loss': 4.0259, 'grad_norm': 1.9488743543624878, 'learning_rate': 0.0004599, 'epoch': 0.65}\n",
            "{'loss': 4.0366, 'grad_norm': 1.916298747062683, 'learning_rate': 0.00046489999999999997, 'epoch': 0.66}\n",
            "{'loss': 4.0406, 'grad_norm': 1.692515254020691, 'learning_rate': 0.0004699, 'epoch': 0.67}\n",
            "{'loss': 3.9854, 'grad_norm': 2.038790702819824, 'learning_rate': 0.0004749, 'epoch': 0.68}\n",
            "{'loss': 3.9605, 'grad_norm': 1.8294883966445923, 'learning_rate': 0.0004799, 'epoch': 0.68}\n",
            "{'loss': 3.9742, 'grad_norm': 1.7525174617767334, 'learning_rate': 0.0004849, 'epoch': 0.69}\n",
            "{'loss': 3.9579, 'grad_norm': 2.0389907360076904, 'learning_rate': 0.0004899, 'epoch': 0.7}\n",
            "{'loss': 3.9333, 'grad_norm': 1.9176439046859741, 'learning_rate': 0.0004949, 'epoch': 0.7}\n",
            "{'loss': 3.916, 'grad_norm': 1.902366042137146, 'learning_rate': 0.0004999000000000001, 'epoch': 0.71}\n",
            "{'loss': 3.9004, 'grad_norm': 1.803318738937378, 'learning_rate': 0.0004994555555555555, 'epoch': 0.72}\n",
            "{'loss': 3.8986, 'grad_norm': 1.9061334133148193, 'learning_rate': 0.0004989, 'epoch': 0.72}\n",
            "{'loss': 3.8816, 'grad_norm': 1.9432355165481567, 'learning_rate': 0.0004983444444444444, 'epoch': 0.73}\n",
            "{'loss': 3.8851, 'grad_norm': 1.9960206747055054, 'learning_rate': 0.0004977888888888889, 'epoch': 0.74}\n",
            "{'loss': 3.8479, 'grad_norm': 1.8257569074630737, 'learning_rate': 0.0004972333333333334, 'epoch': 0.75}\n",
            "{'loss': 3.839, 'grad_norm': 1.70781409740448, 'learning_rate': 0.0004966777777777778, 'epoch': 0.75}\n",
            "{'loss': 3.8628, 'grad_norm': 2.0470404624938965, 'learning_rate': 0.0004961222222222223, 'epoch': 0.76}\n",
            "{'loss': 3.8336, 'grad_norm': 1.782820463180542, 'learning_rate': 0.0004955666666666667, 'epoch': 0.77}\n",
            "{'loss': 3.7975, 'grad_norm': 1.6400703191757202, 'learning_rate': 0.0004950111111111112, 'epoch': 0.77}\n",
            "{'loss': 3.7808, 'grad_norm': 1.732743501663208, 'learning_rate': 0.0004944555555555555, 'epoch': 0.78}\n",
            "{'loss': 3.7836, 'grad_norm': 1.8391293287277222, 'learning_rate': 0.0004939, 'epoch': 0.79}\n",
            "{'loss': 3.7709, 'grad_norm': 1.7917358875274658, 'learning_rate': 0.0004933444444444444, 'epoch': 0.8}\n",
            "{'loss': 3.7547, 'grad_norm': 1.776984691619873, 'learning_rate': 0.0004927888888888889, 'epoch': 0.8}\n",
            "{'loss': 3.7656, 'grad_norm': 1.7300653457641602, 'learning_rate': 0.0004922333333333334, 'epoch': 0.81}\n",
            "{'loss': 3.7154, 'grad_norm': 1.7058875560760498, 'learning_rate': 0.0004916777777777778, 'epoch': 0.82}\n",
            "{'loss': 3.7387, 'grad_norm': 1.682995080947876, 'learning_rate': 0.0004911222222222223, 'epoch': 0.82}\n",
            "{'loss': 3.72, 'grad_norm': 1.7424618005752563, 'learning_rate': 0.0004905666666666666, 'epoch': 0.83}\n",
            "{'loss': 3.7127, 'grad_norm': 1.6659611463546753, 'learning_rate': 0.0004900111111111111, 'epoch': 0.84}\n",
            "{'loss': 3.6937, 'grad_norm': 1.7176237106323242, 'learning_rate': 0.0004894555555555555, 'epoch': 0.85}\n",
            "{'loss': 3.6823, 'grad_norm': 1.6569284200668335, 'learning_rate': 0.0004889, 'epoch': 0.85}\n",
            " 12% 6000/50000 [09:10<1:06:33, 11.02it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.56it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.59it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.25it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.84it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.26it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.42it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.84it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.14it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.93it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.15it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.94it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.41it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.13it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.90it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.80it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.64it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.56it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 3.587228536605835, 'eval_accuracy': 0.43495628237724304, 'eval_runtime': 2.879, 'eval_samples_per_second': 1306.017, 'eval_steps_per_second': 20.493, 'epoch': 0.85}\n",
            " 12% 6000/50000 [09:13<1:06:33, 11.02it/s]\n",
            "100% 59/59 [00:02<00:00, 17.72it/s]\u001b[A\n",
            "{'loss': 3.6843, 'grad_norm': 1.6063722372055054, 'learning_rate': 0.0004883444444444445, 'epoch': 0.86}\n",
            "{'loss': 3.6571, 'grad_norm': 1.6768778562545776, 'learning_rate': 0.0004877888888888889, 'epoch': 0.87}\n",
            "{'loss': 3.6542, 'grad_norm': 1.7059755325317383, 'learning_rate': 0.0004872333333333334, 'epoch': 0.87}\n",
            "{'loss': 3.6256, 'grad_norm': 1.7094519138336182, 'learning_rate': 0.00048667777777777776, 'epoch': 0.88}\n",
            "{'loss': 3.6314, 'grad_norm': 1.6034576892852783, 'learning_rate': 0.00048612222222222225, 'epoch': 0.89}\n",
            "{'loss': 3.6518, 'grad_norm': 1.660384178161621, 'learning_rate': 0.00048556666666666663, 'epoch': 0.9}\n",
            "{'loss': 3.6209, 'grad_norm': 1.7046009302139282, 'learning_rate': 0.0004850111111111111, 'epoch': 0.9}\n",
            "{'loss': 3.6162, 'grad_norm': 1.5695823431015015, 'learning_rate': 0.00048445555555555556, 'epoch': 0.91}\n",
            "{'loss': 3.597, 'grad_norm': 1.7844550609588623, 'learning_rate': 0.0004839, 'epoch': 0.92}\n",
            "{'loss': 3.5788, 'grad_norm': 1.7659534215927124, 'learning_rate': 0.0004833444444444445, 'epoch': 0.92}\n",
            "{'loss': 3.5919, 'grad_norm': 1.5259180068969727, 'learning_rate': 0.00048278888888888887, 'epoch': 0.93}\n",
            "{'loss': 3.593, 'grad_norm': 1.604176640510559, 'learning_rate': 0.00048223333333333336, 'epoch': 0.94}\n",
            "{'loss': 3.5362, 'grad_norm': 1.616741418838501, 'learning_rate': 0.00048167777777777775, 'epoch': 0.95}\n",
            "{'loss': 3.5586, 'grad_norm': 1.8135837316513062, 'learning_rate': 0.00048112222222222224, 'epoch': 0.95}\n",
            "{'loss': 3.544, 'grad_norm': 1.5610575675964355, 'learning_rate': 0.0004805666666666667, 'epoch': 0.96}\n",
            "{'loss': 3.5406, 'grad_norm': 1.588132619857788, 'learning_rate': 0.0004800111111111111, 'epoch': 0.97}\n",
            "{'loss': 3.5155, 'grad_norm': 1.5195035934448242, 'learning_rate': 0.0004794555555555556, 'epoch': 0.97}\n",
            "{'loss': 3.5284, 'grad_norm': 1.6657302379608154, 'learning_rate': 0.0004789, 'epoch': 0.98}\n",
            "{'loss': 3.5041, 'grad_norm': 1.620614767074585, 'learning_rate': 0.0004783444444444445, 'epoch': 0.99}\n",
            "{'loss': 3.4927, 'grad_norm': 1.6916961669921875, 'learning_rate': 0.00047778888888888886, 'epoch': 0.99}\n",
            "{'loss': 3.5252, 'grad_norm': 1.540914535522461, 'learning_rate': 0.00047723333333333335, 'epoch': 1.0}\n",
            "{'loss': 3.4692, 'grad_norm': 1.578593373298645, 'learning_rate': 0.0004766777777777778, 'epoch': 1.01}\n",
            "{'loss': 3.4677, 'grad_norm': 1.5442384481430054, 'learning_rate': 0.0004761222222222222, 'epoch': 1.02}\n",
            "{'loss': 3.4691, 'grad_norm': 1.6539338827133179, 'learning_rate': 0.0004755666666666667, 'epoch': 1.02}\n",
            "{'loss': 3.4644, 'grad_norm': 1.6275484561920166, 'learning_rate': 0.0004750111111111111, 'epoch': 1.03}\n",
            "{'loss': 3.4703, 'grad_norm': 1.6655341386795044, 'learning_rate': 0.0004744555555555556, 'epoch': 1.04}\n",
            "{'loss': 3.4373, 'grad_norm': 1.6643186807632446, 'learning_rate': 0.00047389999999999997, 'epoch': 1.04}\n",
            "{'loss': 3.4505, 'grad_norm': 1.5226671695709229, 'learning_rate': 0.00047334444444444446, 'epoch': 1.05}\n",
            "{'loss': 3.4724, 'grad_norm': 1.532253384590149, 'learning_rate': 0.0004727888888888889, 'epoch': 1.06}\n",
            "{'loss': 3.4395, 'grad_norm': 1.5670472383499146, 'learning_rate': 0.00047223333333333334, 'epoch': 1.07}\n",
            "{'loss': 3.4398, 'grad_norm': 1.6760101318359375, 'learning_rate': 0.0004716777777777778, 'epoch': 1.07}\n",
            "{'loss': 3.4405, 'grad_norm': 1.528918743133545, 'learning_rate': 0.0004711222222222222, 'epoch': 1.08}\n",
            "{'loss': 3.429, 'grad_norm': 1.546841025352478, 'learning_rate': 0.0004705666666666667, 'epoch': 1.09}\n",
            "{'loss': 3.4099, 'grad_norm': 1.6275852918624878, 'learning_rate': 0.0004700111111111111, 'epoch': 1.09}\n",
            "{'loss': 3.4103, 'grad_norm': 1.5200645923614502, 'learning_rate': 0.0004694555555555556, 'epoch': 1.1}\n",
            "{'loss': 3.4131, 'grad_norm': 1.4629961252212524, 'learning_rate': 0.0004689, 'epoch': 1.11}\n",
            "{'loss': 3.3731, 'grad_norm': 1.601324200630188, 'learning_rate': 0.00046834444444444445, 'epoch': 1.12}\n",
            "{'loss': 3.3933, 'grad_norm': 1.5525249242782593, 'learning_rate': 0.0004677888888888889, 'epoch': 1.12}\n",
            "{'loss': 3.3886, 'grad_norm': 1.605045199394226, 'learning_rate': 0.0004672333333333333, 'epoch': 1.13}\n",
            "{'loss': 3.3884, 'grad_norm': 1.7070375680923462, 'learning_rate': 0.0004666777777777778, 'epoch': 1.14}\n",
            " 16% 8000/50000 [12:15<1:03:03, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.56it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 42.28it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 41.90it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 41.95it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 29.41it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.92it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 22.94it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.63it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.29it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 21.83it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.59it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 20.24it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 18.60it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.50it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.14it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 3.303807020187378, 'eval_accuracy': 0.45934033393859863, 'eval_runtime': 2.913, 'eval_samples_per_second': 1290.757, 'eval_steps_per_second': 20.254, 'epoch': 1.14}\n",
            " 16% 8000/50000 [12:18<1:03:03, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 17.32it/s]\u001b[A\n",
            "{'loss': 3.3802, 'grad_norm': 1.488105058670044, 'learning_rate': 0.00046613333333333335, 'epoch': 1.14}\n",
            "{'loss': 3.3759, 'grad_norm': 1.6888887882232666, 'learning_rate': 0.0004655777777777778, 'epoch': 1.15}\n",
            "{'loss': 3.3675, 'grad_norm': 1.5859935283660889, 'learning_rate': 0.0004650222222222222, 'epoch': 1.16}\n",
            "{'loss': 3.3345, 'grad_norm': 1.5671132802963257, 'learning_rate': 0.0004644666666666667, 'epoch': 1.17}\n",
            "{'loss': 3.3587, 'grad_norm': 1.55990469455719, 'learning_rate': 0.0004639111111111111, 'epoch': 1.17}\n",
            "{'loss': 3.3508, 'grad_norm': 1.5011610984802246, 'learning_rate': 0.0004633555555555556, 'epoch': 1.18}\n",
            "{'loss': 3.3357, 'grad_norm': 1.4902920722961426, 'learning_rate': 0.0004628, 'epoch': 1.19}\n",
            "{'loss': 3.3272, 'grad_norm': 1.4666187763214111, 'learning_rate': 0.00046224444444444446, 'epoch': 1.19}\n",
            "{'loss': 3.3405, 'grad_norm': 1.5409969091415405, 'learning_rate': 0.0004616888888888889, 'epoch': 1.2}\n",
            "{'loss': 3.3383, 'grad_norm': 1.4563405513763428, 'learning_rate': 0.00046113333333333334, 'epoch': 1.21}\n",
            "{'loss': 3.3265, 'grad_norm': 1.4728336334228516, 'learning_rate': 0.0004605777777777778, 'epoch': 1.22}\n",
            "{'loss': 3.3235, 'grad_norm': 1.4851535558700562, 'learning_rate': 0.0004600222222222222, 'epoch': 1.22}\n",
            "{'loss': 3.3254, 'grad_norm': 1.4273959398269653, 'learning_rate': 0.0004594666666666667, 'epoch': 1.23}\n",
            "{'loss': 3.3168, 'grad_norm': 1.5060704946517944, 'learning_rate': 0.0004589111111111111, 'epoch': 1.24}\n",
            "{'loss': 3.3129, 'grad_norm': 1.6150351762771606, 'learning_rate': 0.0004583555555555556, 'epoch': 1.24}\n",
            "{'loss': 3.3244, 'grad_norm': 1.4579907655715942, 'learning_rate': 0.0004578, 'epoch': 1.25}\n",
            "{'loss': 3.3178, 'grad_norm': 1.4407891035079956, 'learning_rate': 0.00045724444444444445, 'epoch': 1.26}\n",
            "{'loss': 3.2965, 'grad_norm': 1.4456884860992432, 'learning_rate': 0.0004566888888888889, 'epoch': 1.26}\n",
            "{'loss': 3.2898, 'grad_norm': 1.4100160598754883, 'learning_rate': 0.0004561333333333333, 'epoch': 1.27}\n",
            "{'loss': 3.276, 'grad_norm': 1.4892919063568115, 'learning_rate': 0.0004555777777777778, 'epoch': 1.28}\n",
            "{'loss': 3.2875, 'grad_norm': 1.4569939374923706, 'learning_rate': 0.0004550222222222222, 'epoch': 1.29}\n",
            "{'loss': 3.2676, 'grad_norm': 1.3596569299697876, 'learning_rate': 0.0004544666666666667, 'epoch': 1.29}\n",
            "{'loss': 3.2758, 'grad_norm': 1.552685260772705, 'learning_rate': 0.00045391111111111113, 'epoch': 1.3}\n",
            "{'loss': 3.2688, 'grad_norm': 1.5160599946975708, 'learning_rate': 0.00045335555555555556, 'epoch': 1.31}\n",
            "{'loss': 3.2573, 'grad_norm': 1.5418328046798706, 'learning_rate': 0.0004528, 'epoch': 1.31}\n",
            "{'loss': 3.277, 'grad_norm': 1.4513378143310547, 'learning_rate': 0.00045224444444444444, 'epoch': 1.32}\n",
            "{'loss': 3.2449, 'grad_norm': 1.5188510417938232, 'learning_rate': 0.0004516888888888889, 'epoch': 1.33}\n",
            "{'loss': 3.2291, 'grad_norm': 1.5172326564788818, 'learning_rate': 0.00045113333333333337, 'epoch': 1.34}\n",
            "{'loss': 3.2392, 'grad_norm': 1.5091785192489624, 'learning_rate': 0.0004505777777777778, 'epoch': 1.34}\n",
            "{'loss': 3.2433, 'grad_norm': 1.479843020439148, 'learning_rate': 0.00045002222222222224, 'epoch': 1.35}\n",
            "{'loss': 3.2159, 'grad_norm': 1.4056918621063232, 'learning_rate': 0.0004494666666666667, 'epoch': 1.36}\n",
            "{'loss': 3.2121, 'grad_norm': 1.520641565322876, 'learning_rate': 0.0004489111111111111, 'epoch': 1.36}\n",
            "{'loss': 3.2247, 'grad_norm': 1.4367561340332031, 'learning_rate': 0.00044835555555555555, 'epoch': 1.37}\n",
            "{'loss': 3.242, 'grad_norm': 1.4368870258331299, 'learning_rate': 0.0004478, 'epoch': 1.38}\n",
            "{'loss': 3.2413, 'grad_norm': 1.5332568883895874, 'learning_rate': 0.0004472444444444445, 'epoch': 1.39}\n",
            "{'loss': 3.2443, 'grad_norm': 1.483606219291687, 'learning_rate': 0.0004466888888888889, 'epoch': 1.39}\n",
            "{'loss': 3.209, 'grad_norm': 1.5211567878723145, 'learning_rate': 0.00044613333333333335, 'epoch': 1.4}\n",
            "{'loss': 3.1933, 'grad_norm': 1.4186824560165405, 'learning_rate': 0.0004455777777777778, 'epoch': 1.41}\n",
            "{'loss': 3.2083, 'grad_norm': 1.5659270286560059, 'learning_rate': 0.00044502222222222223, 'epoch': 1.41}\n",
            "{'loss': 3.2096, 'grad_norm': 1.528360366821289, 'learning_rate': 0.00044446666666666666, 'epoch': 1.42}\n",
            " 20% 10000/50000 [15:19<1:00:04, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.12it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.94it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.99it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.87it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.60it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 27.19it/s]\u001b[A\n",
            " 56% 33/59 [00:01<00:01, 23.73it/s]\u001b[A\n",
            " 61% 36/59 [00:01<00:01, 22.15it/s]\u001b[A\n",
            " 66% 39/59 [00:01<00:01, 19.12it/s]\u001b[A\n",
            " 71% 42/59 [00:01<00:00, 18.87it/s]\u001b[A\n",
            " 76% 45/59 [00:01<00:00, 18.78it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 18.65it/s]\u001b[A\n",
            " 83% 49/59 [00:02<00:00, 18.54it/s]\u001b[A\n",
            " 88% 52/59 [00:02<00:00, 20.73it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 19.88it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 3.143036365509033, 'eval_accuracy': 0.47622978687286377, 'eval_runtime': 2.9041, 'eval_samples_per_second': 1294.731, 'eval_steps_per_second': 20.316, 'epoch': 1.42}\n",
            " 20% 10000/50000 [15:22<1:00:04, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 18.30it/s]\u001b[A\n",
            "{'loss': 3.1647, 'grad_norm': 1.41123366355896, 'learning_rate': 0.0004439111111111111, 'epoch': 1.43}\n",
            "{'loss': 3.1994, 'grad_norm': 1.3446849584579468, 'learning_rate': 0.0004433555555555556, 'epoch': 1.44}\n",
            "{'loss': 3.1873, 'grad_norm': 1.453016996383667, 'learning_rate': 0.00044280000000000003, 'epoch': 1.44}\n",
            "{'loss': 3.1727, 'grad_norm': 1.4767152070999146, 'learning_rate': 0.00044224444444444447, 'epoch': 1.45}\n",
            "{'loss': 3.1785, 'grad_norm': 1.4585248231887817, 'learning_rate': 0.0004416888888888889, 'epoch': 1.46}\n",
            "{'loss': 3.1813, 'grad_norm': 1.548577904701233, 'learning_rate': 0.00044114444444444444, 'epoch': 1.46}\n",
            "{'loss': 3.1728, 'grad_norm': 1.4268897771835327, 'learning_rate': 0.0004405888888888889, 'epoch': 1.47}\n",
            "{'loss': 3.1822, 'grad_norm': 1.541985034942627, 'learning_rate': 0.00044003333333333337, 'epoch': 1.48}\n",
            "{'loss': 3.1916, 'grad_norm': 1.3154488801956177, 'learning_rate': 0.0004394777777777778, 'epoch': 1.49}\n",
            "{'loss': 3.1779, 'grad_norm': 1.6010005474090576, 'learning_rate': 0.00043892222222222224, 'epoch': 1.49}\n",
            "{'loss': 3.1661, 'grad_norm': 1.3560305833816528, 'learning_rate': 0.0004383666666666667, 'epoch': 1.5}\n",
            "{'loss': 3.1531, 'grad_norm': 1.363037347793579, 'learning_rate': 0.0004378111111111111, 'epoch': 1.51}\n",
            "{'loss': 3.1833, 'grad_norm': 1.4812463521957397, 'learning_rate': 0.00043725555555555555, 'epoch': 1.51}\n",
            "{'loss': 3.1638, 'grad_norm': 1.3978859186172485, 'learning_rate': 0.0004367, 'epoch': 1.52}\n",
            "{'loss': 3.158, 'grad_norm': 1.3894670009613037, 'learning_rate': 0.0004361444444444445, 'epoch': 1.53}\n",
            "{'loss': 3.129, 'grad_norm': 1.3339521884918213, 'learning_rate': 0.0004355888888888889, 'epoch': 1.53}\n",
            "{'loss': 3.1658, 'grad_norm': 1.360546350479126, 'learning_rate': 0.00043503333333333335, 'epoch': 1.54}\n",
            "{'loss': 3.143, 'grad_norm': 1.4750300645828247, 'learning_rate': 0.0004344777777777778, 'epoch': 1.55}\n",
            "{'loss': 3.1431, 'grad_norm': 1.4595571756362915, 'learning_rate': 0.00043392222222222223, 'epoch': 1.56}\n",
            "{'loss': 3.1193, 'grad_norm': 1.4199248552322388, 'learning_rate': 0.00043336666666666667, 'epoch': 1.56}\n",
            "{'loss': 3.1112, 'grad_norm': 1.3894586563110352, 'learning_rate': 0.0004328111111111111, 'epoch': 1.57}\n",
            "{'loss': 3.1064, 'grad_norm': 1.5258523225784302, 'learning_rate': 0.0004322555555555556, 'epoch': 1.58}\n",
            "{'loss': 3.135, 'grad_norm': 1.5258833169937134, 'learning_rate': 0.0004317, 'epoch': 1.58}\n",
            "{'loss': 3.125, 'grad_norm': 1.3777168989181519, 'learning_rate': 0.00043114444444444447, 'epoch': 1.59}\n",
            "{'loss': 3.124, 'grad_norm': 1.3257840871810913, 'learning_rate': 0.0004305888888888889, 'epoch': 1.6}\n",
            "{'loss': 3.1052, 'grad_norm': 1.419937014579773, 'learning_rate': 0.00043003333333333334, 'epoch': 1.61}\n",
            "{'loss': 3.0903, 'grad_norm': 1.5679596662521362, 'learning_rate': 0.0004294777777777778, 'epoch': 1.61}\n",
            "{'loss': 3.1236, 'grad_norm': 1.3607051372528076, 'learning_rate': 0.0004289222222222222, 'epoch': 1.62}\n",
            "{'loss': 3.1118, 'grad_norm': 1.3020391464233398, 'learning_rate': 0.0004283666666666667, 'epoch': 1.63}\n",
            "{'loss': 3.1164, 'grad_norm': 1.4673757553100586, 'learning_rate': 0.0004278111111111111, 'epoch': 1.63}\n",
            "{'loss': 3.1094, 'grad_norm': 1.420607566833496, 'learning_rate': 0.0004272555555555556, 'epoch': 1.64}\n",
            "{'loss': 3.0942, 'grad_norm': 1.4578458070755005, 'learning_rate': 0.0004267, 'epoch': 1.65}\n",
            "{'loss': 3.0954, 'grad_norm': 1.3807710409164429, 'learning_rate': 0.00042614444444444445, 'epoch': 1.66}\n",
            "{'loss': 3.1235, 'grad_norm': 1.4403568506240845, 'learning_rate': 0.0004255888888888889, 'epoch': 1.66}\n",
            "{'loss': 3.0924, 'grad_norm': 1.4344700574874878, 'learning_rate': 0.00042503333333333333, 'epoch': 1.67}\n",
            "{'loss': 3.1089, 'grad_norm': 1.4102541208267212, 'learning_rate': 0.0004244777777777778, 'epoch': 1.68}\n",
            "{'loss': 3.082, 'grad_norm': 1.5344537496566772, 'learning_rate': 0.0004239222222222222, 'epoch': 1.68}\n",
            "{'loss': 3.0859, 'grad_norm': 1.575196385383606, 'learning_rate': 0.0004233666666666667, 'epoch': 1.69}\n",
            "{'loss': 3.0673, 'grad_norm': 1.3658156394958496, 'learning_rate': 0.00042281111111111113, 'epoch': 1.7}\n",
            "{'loss': 3.0856, 'grad_norm': 1.4382047653198242, 'learning_rate': 0.00042225555555555557, 'epoch': 1.71}\n",
            " 24% 12000/50000 [18:23<57:01, 11.11it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 45.46it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.63it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.08it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.10it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.16it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.27it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.75it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.08it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.93it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.10it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.52it/s]\u001b[A\n",
            " 78% 46/59 [00:01<00:00, 19.25it/s]\u001b[A\n",
            " 81% 48/59 [00:01<00:00, 17.89it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 19.09it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.95it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.61it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.68it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 3.0079877376556396, 'eval_accuracy': 0.48873335123062134, 'eval_runtime': 2.8593, 'eval_samples_per_second': 1315.0, 'eval_steps_per_second': 20.634, 'epoch': 1.71}\n",
            " 24% 12000/50000 [18:26<57:01, 11.11it/s]\n",
            "100% 59/59 [00:02<00:00, 17.87it/s]\u001b[A\n",
            "{'loss': 3.0604, 'grad_norm': 1.337740182876587, 'learning_rate': 0.0004217, 'epoch': 1.71}\n",
            "{'loss': 3.0873, 'grad_norm': 1.4805165529251099, 'learning_rate': 0.00042114444444444444, 'epoch': 1.72}\n",
            "{'loss': 3.0842, 'grad_norm': 1.367556095123291, 'learning_rate': 0.00042058888888888893, 'epoch': 1.73}\n",
            "{'loss': 3.0778, 'grad_norm': 1.4190521240234375, 'learning_rate': 0.0004200333333333333, 'epoch': 1.73}\n",
            "{'loss': 3.0686, 'grad_norm': 1.4332445859909058, 'learning_rate': 0.0004194777777777778, 'epoch': 1.74}\n",
            "{'loss': 3.0356, 'grad_norm': 1.3469525575637817, 'learning_rate': 0.0004189222222222222, 'epoch': 1.75}\n",
            "{'loss': 3.0677, 'grad_norm': 1.4743733406066895, 'learning_rate': 0.0004183666666666667, 'epoch': 1.76}\n",
            "{'loss': 3.0672, 'grad_norm': 1.4256641864776611, 'learning_rate': 0.0004178111111111111, 'epoch': 1.76}\n",
            "{'loss': 3.0481, 'grad_norm': 1.3694264888763428, 'learning_rate': 0.00041725555555555555, 'epoch': 1.77}\n",
            "{'loss': 3.064, 'grad_norm': 1.4304035902023315, 'learning_rate': 0.00041670000000000005, 'epoch': 1.78}\n",
            "{'loss': 3.0534, 'grad_norm': 1.5390293598175049, 'learning_rate': 0.0004161555555555556, 'epoch': 1.78}\n",
            "{'loss': 3.0288, 'grad_norm': 1.4363995790481567, 'learning_rate': 0.0004156, 'epoch': 1.79}\n",
            "{'loss': 3.0399, 'grad_norm': 1.481797456741333, 'learning_rate': 0.00041504444444444446, 'epoch': 1.8}\n",
            "{'loss': 3.0311, 'grad_norm': 1.4570245742797852, 'learning_rate': 0.0004144888888888889, 'epoch': 1.8}\n",
            "{'loss': 3.0025, 'grad_norm': 1.3325014114379883, 'learning_rate': 0.00041393333333333333, 'epoch': 1.81}\n",
            "{'loss': 3.0247, 'grad_norm': 1.3879435062408447, 'learning_rate': 0.0004133777777777778, 'epoch': 1.82}\n",
            "{'loss': 3.0702, 'grad_norm': 1.5936187505722046, 'learning_rate': 0.0004128222222222222, 'epoch': 1.83}\n",
            "{'loss': 3.0223, 'grad_norm': 1.4265668392181396, 'learning_rate': 0.0004122666666666667, 'epoch': 1.83}\n",
            "{'loss': 3.0321, 'grad_norm': 1.3956222534179688, 'learning_rate': 0.00041171111111111113, 'epoch': 1.84}\n",
            "{'loss': 3.0388, 'grad_norm': 1.3823333978652954, 'learning_rate': 0.00041115555555555557, 'epoch': 1.85}\n",
            "{'loss': 3.0098, 'grad_norm': 1.3633569478988647, 'learning_rate': 0.0004106, 'epoch': 1.85}\n",
            "{'loss': 3.024, 'grad_norm': 1.3110904693603516, 'learning_rate': 0.00041004444444444444, 'epoch': 1.86}\n",
            "{'loss': 3.0187, 'grad_norm': 1.2721774578094482, 'learning_rate': 0.00040948888888888893, 'epoch': 1.87}\n",
            "{'loss': 3.038, 'grad_norm': 1.5214043855667114, 'learning_rate': 0.0004089333333333333, 'epoch': 1.88}\n",
            "{'loss': 3.0152, 'grad_norm': 1.2931069135665894, 'learning_rate': 0.0004083777777777778, 'epoch': 1.88}\n",
            "{'loss': 3.0152, 'grad_norm': 1.374658465385437, 'learning_rate': 0.0004078222222222222, 'epoch': 1.89}\n",
            "{'loss': 3.0114, 'grad_norm': 1.373103141784668, 'learning_rate': 0.0004072666666666667, 'epoch': 1.9}\n",
            "{'loss': 2.9925, 'grad_norm': 1.4454882144927979, 'learning_rate': 0.0004067111111111111, 'epoch': 1.9}\n",
            "{'loss': 3.0198, 'grad_norm': 1.347373604774475, 'learning_rate': 0.00040615555555555556, 'epoch': 1.91}\n",
            "{'loss': 3.0086, 'grad_norm': 1.3388712406158447, 'learning_rate': 0.00040560000000000005, 'epoch': 1.92}\n",
            "{'loss': 2.9947, 'grad_norm': 1.3895891904830933, 'learning_rate': 0.00040504444444444443, 'epoch': 1.93}\n",
            "{'loss': 2.9893, 'grad_norm': 1.3561955690383911, 'learning_rate': 0.0004044888888888889, 'epoch': 1.93}\n",
            "{'loss': 2.9868, 'grad_norm': 1.3401683568954468, 'learning_rate': 0.0004039333333333333, 'epoch': 1.94}\n",
            "{'loss': 2.9843, 'grad_norm': 1.3547558784484863, 'learning_rate': 0.0004033777777777778, 'epoch': 1.95}\n",
            "{'loss': 2.9971, 'grad_norm': 1.332871675491333, 'learning_rate': 0.00040282222222222223, 'epoch': 1.95}\n",
            "{'loss': 3.0111, 'grad_norm': 1.3901952505111694, 'learning_rate': 0.00040226666666666667, 'epoch': 1.96}\n",
            "{'loss': 2.9998, 'grad_norm': 1.364493727684021, 'learning_rate': 0.00040171111111111116, 'epoch': 1.97}\n",
            "{'loss': 2.9885, 'grad_norm': 1.465483546257019, 'learning_rate': 0.00040115555555555554, 'epoch': 1.98}\n",
            "{'loss': 2.9615, 'grad_norm': 1.3370736837387085, 'learning_rate': 0.00040060000000000003, 'epoch': 1.98}\n",
            "{'loss': 2.9887, 'grad_norm': 1.4023910760879517, 'learning_rate': 0.0004000444444444444, 'epoch': 1.99}\n",
            " 28% 14000/50000 [21:27<54:10, 11.07it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 40.67it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 42.54it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 40.77it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 41.00it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 33.41it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.96it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 24.18it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.31it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.11it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.22it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.67it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.22it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.02it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.82it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.57it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.47it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.9357378482818604, 'eval_accuracy': 0.49895569682121277, 'eval_runtime': 2.8621, 'eval_samples_per_second': 1313.743, 'eval_steps_per_second': 20.615, 'epoch': 1.99}\n",
            " 28% 14000/50000 [21:30<54:10, 11.07it/s]\n",
            "100% 59/59 [00:02<00:00, 17.61it/s]\u001b[A\n",
            "{'loss': 2.9863, 'grad_norm': 1.4251084327697754, 'learning_rate': 0.0003994888888888889, 'epoch': 2.0}\n",
            "{'loss': 2.9471, 'grad_norm': 1.3859527111053467, 'learning_rate': 0.0003989333333333333, 'epoch': 2.0}\n",
            "{'loss': 2.9444, 'grad_norm': 1.3732141256332397, 'learning_rate': 0.0003983777777777778, 'epoch': 2.01}\n",
            "{'loss': 2.9723, 'grad_norm': 1.377246379852295, 'learning_rate': 0.00039782222222222227, 'epoch': 2.02}\n",
            "{'loss': 2.9422, 'grad_norm': 1.3962297439575195, 'learning_rate': 0.00039726666666666666, 'epoch': 2.03}\n",
            "{'loss': 2.9636, 'grad_norm': 1.4519288539886475, 'learning_rate': 0.00039671111111111115, 'epoch': 2.03}\n",
            "{'loss': 2.9777, 'grad_norm': 1.2988452911376953, 'learning_rate': 0.00039615555555555553, 'epoch': 2.04}\n",
            "{'loss': 2.9584, 'grad_norm': 1.363218069076538, 'learning_rate': 0.0003956, 'epoch': 2.05}\n",
            "{'loss': 2.9561, 'grad_norm': 1.3683642148971558, 'learning_rate': 0.0003950444444444444, 'epoch': 2.05}\n",
            "{'loss': 2.9506, 'grad_norm': 1.437911868095398, 'learning_rate': 0.0003944888888888889, 'epoch': 2.06}\n",
            "{'loss': 2.9383, 'grad_norm': 1.4129384756088257, 'learning_rate': 0.0003939333333333334, 'epoch': 2.07}\n",
            "{'loss': 2.9525, 'grad_norm': 1.4229474067687988, 'learning_rate': 0.00039337777777777777, 'epoch': 2.07}\n",
            "{'loss': 2.9557, 'grad_norm': 1.3096634149551392, 'learning_rate': 0.0003928333333333333, 'epoch': 2.08}\n",
            "{'loss': 2.9342, 'grad_norm': 1.356676459312439, 'learning_rate': 0.0003922777777777778, 'epoch': 2.09}\n",
            "{'loss': 2.9365, 'grad_norm': 1.3187909126281738, 'learning_rate': 0.00039172222222222223, 'epoch': 2.1}\n",
            "{'loss': 2.9486, 'grad_norm': 1.3163330554962158, 'learning_rate': 0.00039116666666666667, 'epoch': 2.1}\n",
            "{'loss': 2.9533, 'grad_norm': 1.3152929544448853, 'learning_rate': 0.00039061111111111116, 'epoch': 2.11}\n",
            "{'loss': 2.9245, 'grad_norm': 1.35783851146698, 'learning_rate': 0.00039005555555555554, 'epoch': 2.12}\n",
            "{'loss': 2.9263, 'grad_norm': 1.313631296157837, 'learning_rate': 0.00038950000000000003, 'epoch': 2.12}\n",
            "{'loss': 2.9194, 'grad_norm': 1.3694732189178467, 'learning_rate': 0.0003889444444444444, 'epoch': 2.13}\n",
            "{'loss': 2.9098, 'grad_norm': 1.5123213529586792, 'learning_rate': 0.0003883888888888889, 'epoch': 2.14}\n",
            "{'loss': 2.9305, 'grad_norm': 1.3253802061080933, 'learning_rate': 0.0003878333333333333, 'epoch': 2.15}\n",
            "{'loss': 2.9031, 'grad_norm': 1.5143046379089355, 'learning_rate': 0.0003872777777777778, 'epoch': 2.15}\n",
            "{'loss': 2.9255, 'grad_norm': 1.3327637910842896, 'learning_rate': 0.0003867222222222223, 'epoch': 2.16}\n",
            "{'loss': 2.9202, 'grad_norm': 1.4340147972106934, 'learning_rate': 0.00038616666666666666, 'epoch': 2.17}\n",
            "{'loss': 2.9294, 'grad_norm': 1.3803150653839111, 'learning_rate': 0.00038561111111111115, 'epoch': 2.17}\n",
            "{'loss': 2.9031, 'grad_norm': 1.37562096118927, 'learning_rate': 0.00038505555555555553, 'epoch': 2.18}\n",
            "{'loss': 2.8997, 'grad_norm': 1.5275909900665283, 'learning_rate': 0.0003845, 'epoch': 2.19}\n",
            "{'loss': 2.9083, 'grad_norm': 1.3353171348571777, 'learning_rate': 0.0003839444444444444, 'epoch': 2.2}\n",
            "{'loss': 2.9036, 'grad_norm': 1.3153184652328491, 'learning_rate': 0.0003833888888888889, 'epoch': 2.2}\n",
            "{'loss': 2.9081, 'grad_norm': 1.3665863275527954, 'learning_rate': 0.0003828333333333334, 'epoch': 2.21}\n",
            "{'loss': 2.9248, 'grad_norm': 1.4317301511764526, 'learning_rate': 0.00038227777777777777, 'epoch': 2.22}\n",
            "{'loss': 2.9112, 'grad_norm': 1.3068907260894775, 'learning_rate': 0.00038172222222222226, 'epoch': 2.22}\n",
            "{'loss': 2.9066, 'grad_norm': 1.4221080541610718, 'learning_rate': 0.00038116666666666664, 'epoch': 2.23}\n",
            "{'loss': 2.9182, 'grad_norm': 1.4282855987548828, 'learning_rate': 0.00038061111111111113, 'epoch': 2.24}\n",
            "{'loss': 2.912, 'grad_norm': 1.4113125801086426, 'learning_rate': 0.0003800555555555555, 'epoch': 2.25}\n",
            "{'loss': 2.9131, 'grad_norm': 1.508945345878601, 'learning_rate': 0.0003795, 'epoch': 2.25}\n",
            "{'loss': 2.9008, 'grad_norm': 1.4227712154388428, 'learning_rate': 0.00037894444444444445, 'epoch': 2.26}\n",
            "{'loss': 2.9334, 'grad_norm': 1.3249924182891846, 'learning_rate': 0.0003783888888888889, 'epoch': 2.27}\n",
            "{'loss': 2.8932, 'grad_norm': 1.3829808235168457, 'learning_rate': 0.0003778333333333334, 'epoch': 2.27}\n",
            " 32% 16000/50000 [24:32<51:02, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 42.91it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.18it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.22it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.68it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.82it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.75it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 22.75it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.42it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.49it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 22.00it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 20.77it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.99it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 18.45it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.42it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 19.11it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.8895633220672607, 'eval_accuracy': 0.5024212598800659, 'eval_runtime': 2.8346, 'eval_samples_per_second': 1326.449, 'eval_steps_per_second': 20.814, 'epoch': 2.27}\n",
            " 32% 16000/50000 [24:35<51:02, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 18.86it/s]\u001b[A\n",
            "{'loss': 2.9, 'grad_norm': 1.3332633972167969, 'learning_rate': 0.00037727777777777776, 'epoch': 2.28}\n",
            "{'loss': 2.8825, 'grad_norm': 1.3668849468231201, 'learning_rate': 0.00037672222222222225, 'epoch': 2.29}\n",
            "{'loss': 2.8854, 'grad_norm': 1.3966172933578491, 'learning_rate': 0.00037616666666666663, 'epoch': 2.3}\n",
            "{'loss': 2.8957, 'grad_norm': 1.3534919023513794, 'learning_rate': 0.0003756111111111111, 'epoch': 2.3}\n",
            "{'loss': 2.8725, 'grad_norm': 1.4364955425262451, 'learning_rate': 0.00037505555555555556, 'epoch': 2.31}\n",
            "{'loss': 2.8756, 'grad_norm': 1.3924154043197632, 'learning_rate': 0.0003745, 'epoch': 2.32}\n",
            "{'loss': 2.8677, 'grad_norm': 1.4501837491989136, 'learning_rate': 0.0003739444444444445, 'epoch': 2.32}\n",
            "{'loss': 2.8625, 'grad_norm': 1.4178876876831055, 'learning_rate': 0.00037338888888888887, 'epoch': 2.33}\n",
            "{'loss': 2.8726, 'grad_norm': 1.3888885974884033, 'learning_rate': 0.00037283333333333336, 'epoch': 2.34}\n",
            "{'loss': 2.8621, 'grad_norm': 1.3070532083511353, 'learning_rate': 0.0003722777777777778, 'epoch': 2.34}\n",
            "{'loss': 2.8714, 'grad_norm': 1.3759015798568726, 'learning_rate': 0.00037172222222222223, 'epoch': 2.35}\n",
            "{'loss': 2.8785, 'grad_norm': 1.4835174083709717, 'learning_rate': 0.00037116666666666667, 'epoch': 2.36}\n",
            "{'loss': 2.8719, 'grad_norm': 1.3365741968154907, 'learning_rate': 0.00037062222222222226, 'epoch': 2.37}\n",
            "{'loss': 2.8503, 'grad_norm': 1.3196066617965698, 'learning_rate': 0.00037006666666666664, 'epoch': 2.37}\n",
            "{'loss': 2.8732, 'grad_norm': 1.344361662864685, 'learning_rate': 0.00036951111111111114, 'epoch': 2.38}\n",
            "{'loss': 2.8865, 'grad_norm': 1.4439120292663574, 'learning_rate': 0.0003689555555555555, 'epoch': 2.39}\n",
            "{'loss': 2.8613, 'grad_norm': 1.3310736417770386, 'learning_rate': 0.0003684, 'epoch': 2.39}\n",
            "{'loss': 2.8846, 'grad_norm': 1.3286244869232178, 'learning_rate': 0.00036784444444444445, 'epoch': 2.4}\n",
            "{'loss': 2.8662, 'grad_norm': 1.325556993484497, 'learning_rate': 0.0003672888888888889, 'epoch': 2.41}\n",
            "{'loss': 2.863, 'grad_norm': 1.391210675239563, 'learning_rate': 0.0003667333333333334, 'epoch': 2.42}\n",
            "{'loss': 2.8539, 'grad_norm': 1.307623267173767, 'learning_rate': 0.00036617777777777776, 'epoch': 2.42}\n",
            "{'loss': 2.8657, 'grad_norm': 1.3386714458465576, 'learning_rate': 0.00036562222222222225, 'epoch': 2.43}\n",
            "{'loss': 2.865, 'grad_norm': 1.2729675769805908, 'learning_rate': 0.00036506666666666663, 'epoch': 2.44}\n",
            "{'loss': 2.8487, 'grad_norm': 1.320873737335205, 'learning_rate': 0.0003645111111111111, 'epoch': 2.44}\n",
            "{'loss': 2.8567, 'grad_norm': 1.2652478218078613, 'learning_rate': 0.00036395555555555556, 'epoch': 2.45}\n",
            "{'loss': 2.8445, 'grad_norm': 1.3963590860366821, 'learning_rate': 0.0003634, 'epoch': 2.46}\n",
            "{'loss': 2.8527, 'grad_norm': 1.3743737936019897, 'learning_rate': 0.0003628444444444445, 'epoch': 2.47}\n",
            "{'loss': 2.8475, 'grad_norm': 1.408905267715454, 'learning_rate': 0.00036228888888888887, 'epoch': 2.47}\n",
            "{'loss': 2.8362, 'grad_norm': 1.3836292028427124, 'learning_rate': 0.00036173333333333336, 'epoch': 2.48}\n",
            "{'loss': 2.8536, 'grad_norm': 1.3619375228881836, 'learning_rate': 0.00036117777777777774, 'epoch': 2.49}\n",
            "{'loss': 2.8352, 'grad_norm': 1.3866593837738037, 'learning_rate': 0.00036062222222222224, 'epoch': 2.49}\n",
            "{'loss': 2.8554, 'grad_norm': 1.3018088340759277, 'learning_rate': 0.00036006666666666667, 'epoch': 2.5}\n",
            "{'loss': 2.8662, 'grad_norm': 1.3568204641342163, 'learning_rate': 0.0003595111111111111, 'epoch': 2.51}\n",
            "{'loss': 2.846, 'grad_norm': 1.4073549509048462, 'learning_rate': 0.0003589555555555556, 'epoch': 2.52}\n",
            "{'loss': 2.8308, 'grad_norm': 1.3308675289154053, 'learning_rate': 0.0003584, 'epoch': 2.52}\n",
            "{'loss': 2.8403, 'grad_norm': 1.3299092054367065, 'learning_rate': 0.0003578444444444445, 'epoch': 2.53}\n",
            "{'loss': 2.8353, 'grad_norm': 1.3396939039230347, 'learning_rate': 0.0003572888888888889, 'epoch': 2.54}\n",
            "{'loss': 2.8312, 'grad_norm': 1.3471553325653076, 'learning_rate': 0.00035673333333333335, 'epoch': 2.54}\n",
            "{'loss': 2.8258, 'grad_norm': 1.3829963207244873, 'learning_rate': 0.0003561777777777778, 'epoch': 2.55}\n",
            "{'loss': 2.8168, 'grad_norm': 1.3288530111312866, 'learning_rate': 0.0003556222222222222, 'epoch': 2.56}\n",
            " 36% 18000/50000 [27:36<48:11, 11.07it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 42.49it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 41.50it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 40.35it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 40.75it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 29.66it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 25.14it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.08it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.60it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.57it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.93it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.44it/s]\u001b[A\n",
            " 78% 46/59 [00:01<00:00, 19.16it/s]\u001b[A\n",
            " 81% 48/59 [00:01<00:00, 18.96it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 18.72it/s]\u001b[A\n",
            " 88% 52/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 92% 54/59 [00:02<00:00, 18.58it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.45it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.7894930839538574, 'eval_accuracy': 0.5160016417503357, 'eval_runtime': 2.9217, 'eval_samples_per_second': 1286.91, 'eval_steps_per_second': 20.194, 'epoch': 2.56}\n",
            " 36% 18000/50000 [27:38<48:11, 11.07it/s]\n",
            "100% 59/59 [00:02<00:00, 18.38it/s]\u001b[A\n",
            "{'loss': 2.8406, 'grad_norm': 1.3094249963760376, 'learning_rate': 0.00035506666666666666, 'epoch': 2.57}\n",
            "{'loss': 2.8356, 'grad_norm': 1.3141924142837524, 'learning_rate': 0.0003545111111111111, 'epoch': 2.57}\n",
            "{'loss': 2.8312, 'grad_norm': 1.350602149963379, 'learning_rate': 0.0003539555555555556, 'epoch': 2.58}\n",
            "{'loss': 2.8064, 'grad_norm': 1.3372011184692383, 'learning_rate': 0.0003534, 'epoch': 2.59}\n",
            "{'loss': 2.8248, 'grad_norm': 1.375577449798584, 'learning_rate': 0.00035284444444444446, 'epoch': 2.59}\n",
            "{'loss': 2.8159, 'grad_norm': 1.420037865638733, 'learning_rate': 0.0003522888888888889, 'epoch': 2.6}\n",
            "{'loss': 2.8186, 'grad_norm': 1.427672028541565, 'learning_rate': 0.00035173333333333334, 'epoch': 2.61}\n",
            "{'loss': 2.8021, 'grad_norm': 1.3014181852340698, 'learning_rate': 0.00035117777777777777, 'epoch': 2.61}\n",
            "{'loss': 2.8262, 'grad_norm': 1.4761792421340942, 'learning_rate': 0.0003506222222222222, 'epoch': 2.62}\n",
            "{'loss': 2.8064, 'grad_norm': 1.3358594179153442, 'learning_rate': 0.0003500666666666667, 'epoch': 2.63}\n",
            "{'loss': 2.8209, 'grad_norm': 1.398123025894165, 'learning_rate': 0.00034951111111111114, 'epoch': 2.64}\n",
            "{'loss': 2.8429, 'grad_norm': 1.3018907308578491, 'learning_rate': 0.0003489555555555556, 'epoch': 2.64}\n",
            "{'loss': 2.7971, 'grad_norm': 1.4081311225891113, 'learning_rate': 0.0003484, 'epoch': 2.65}\n",
            "{'loss': 2.8169, 'grad_norm': 1.4299479722976685, 'learning_rate': 0.00034785555555555555, 'epoch': 2.66}\n",
            "{'loss': 2.823, 'grad_norm': 1.3157927989959717, 'learning_rate': 0.0003473, 'epoch': 2.66}\n",
            "{'loss': 2.7963, 'grad_norm': 1.2611275911331177, 'learning_rate': 0.0003467444444444445, 'epoch': 2.67}\n",
            "{'loss': 2.8203, 'grad_norm': 1.316996693611145, 'learning_rate': 0.0003461888888888889, 'epoch': 2.68}\n",
            "{'loss': 2.8018, 'grad_norm': 1.3465980291366577, 'learning_rate': 0.00034563333333333335, 'epoch': 2.69}\n",
            "{'loss': 2.8056, 'grad_norm': 1.3151111602783203, 'learning_rate': 0.0003450777777777778, 'epoch': 2.69}\n",
            "{'loss': 2.8356, 'grad_norm': 1.347973346710205, 'learning_rate': 0.0003445222222222222, 'epoch': 2.7}\n",
            "{'loss': 2.7859, 'grad_norm': 1.406685471534729, 'learning_rate': 0.00034396666666666666, 'epoch': 2.71}\n",
            "{'loss': 2.8105, 'grad_norm': 1.3177624940872192, 'learning_rate': 0.0003434111111111111, 'epoch': 2.71}\n",
            "{'loss': 2.8155, 'grad_norm': 1.3887079954147339, 'learning_rate': 0.0003428555555555556, 'epoch': 2.72}\n",
            "{'loss': 2.7886, 'grad_norm': 1.2924917936325073, 'learning_rate': 0.0003423, 'epoch': 2.73}\n",
            "{'loss': 2.8164, 'grad_norm': 1.3329172134399414, 'learning_rate': 0.00034174444444444446, 'epoch': 2.74}\n",
            "{'loss': 2.8041, 'grad_norm': 1.3149000406265259, 'learning_rate': 0.0003411888888888889, 'epoch': 2.74}\n",
            "{'loss': 2.7913, 'grad_norm': 1.361048698425293, 'learning_rate': 0.00034063333333333334, 'epoch': 2.75}\n",
            "{'loss': 2.7896, 'grad_norm': 1.3230783939361572, 'learning_rate': 0.0003400777777777778, 'epoch': 2.76}\n",
            "{'loss': 2.7886, 'grad_norm': 1.3476921319961548, 'learning_rate': 0.0003395222222222222, 'epoch': 2.76}\n",
            "{'loss': 2.8023, 'grad_norm': 1.2640457153320312, 'learning_rate': 0.0003389666666666667, 'epoch': 2.77}\n",
            "{'loss': 2.8059, 'grad_norm': 1.340559959411621, 'learning_rate': 0.00033841111111111114, 'epoch': 2.78}\n",
            "{'loss': 2.8166, 'grad_norm': 1.3957651853561401, 'learning_rate': 0.0003378555555555556, 'epoch': 2.79}\n",
            "{'loss': 2.7856, 'grad_norm': 1.2999366521835327, 'learning_rate': 0.0003373, 'epoch': 2.79}\n",
            "{'loss': 2.7808, 'grad_norm': 1.3962607383728027, 'learning_rate': 0.00033674444444444445, 'epoch': 2.8}\n",
            "{'loss': 2.7949, 'grad_norm': 1.3639063835144043, 'learning_rate': 0.0003361888888888889, 'epoch': 2.81}\n",
            "{'loss': 2.8178, 'grad_norm': 1.3497250080108643, 'learning_rate': 0.0003356333333333333, 'epoch': 2.81}\n",
            "{'loss': 2.7897, 'grad_norm': 1.3891899585723877, 'learning_rate': 0.00033507777777777776, 'epoch': 2.82}\n",
            "{'loss': 2.7969, 'grad_norm': 1.3351136445999146, 'learning_rate': 0.00033452222222222225, 'epoch': 2.83}\n",
            "{'loss': 2.7711, 'grad_norm': 1.3244431018829346, 'learning_rate': 0.0003339666666666667, 'epoch': 2.84}\n",
            "{'loss': 2.7823, 'grad_norm': 1.3353554010391235, 'learning_rate': 0.0003334111111111111, 'epoch': 2.84}\n",
            " 40% 20000/50000 [30:40<45:04, 11.09it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.98it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.49it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.11it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.35it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 30.15it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 25.29it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.18it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.88it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.49it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.42it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.85it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.34it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.08it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.90it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.72it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.53it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.719897985458374, 'eval_accuracy': 0.5192438364028931, 'eval_runtime': 2.8765, 'eval_samples_per_second': 1307.147, 'eval_steps_per_second': 20.511, 'epoch': 2.84}\n",
            " 40% 20000/50000 [30:42<45:04, 11.09it/s]\n",
            "100% 59/59 [00:02<00:00, 17.45it/s]\u001b[A\n",
            "{'loss': 2.7722, 'grad_norm': 1.3388190269470215, 'learning_rate': 0.00033285555555555556, 'epoch': 2.85}\n",
            "{'loss': 2.796, 'grad_norm': 1.4068093299865723, 'learning_rate': 0.0003323, 'epoch': 2.86}\n",
            "{'loss': 2.776, 'grad_norm': 1.3185063600540161, 'learning_rate': 0.00033174444444444444, 'epoch': 2.86}\n",
            "{'loss': 2.7873, 'grad_norm': 1.5411877632141113, 'learning_rate': 0.0003311888888888889, 'epoch': 2.87}\n",
            "{'loss': 2.7801, 'grad_norm': 1.2865304946899414, 'learning_rate': 0.00033063333333333336, 'epoch': 2.88}\n",
            "{'loss': 2.7794, 'grad_norm': 1.3673533201217651, 'learning_rate': 0.0003300777777777778, 'epoch': 2.88}\n",
            "{'loss': 2.7706, 'grad_norm': 1.2840664386749268, 'learning_rate': 0.00032952222222222224, 'epoch': 2.89}\n",
            "{'loss': 2.7792, 'grad_norm': 1.28819739818573, 'learning_rate': 0.0003289666666666667, 'epoch': 2.9}\n",
            "{'loss': 2.7629, 'grad_norm': 1.366073489189148, 'learning_rate': 0.0003284111111111111, 'epoch': 2.91}\n",
            "{'loss': 2.7658, 'grad_norm': 1.4062491655349731, 'learning_rate': 0.00032785555555555555, 'epoch': 2.91}\n",
            "{'loss': 2.7546, 'grad_norm': 1.2622623443603516, 'learning_rate': 0.0003273, 'epoch': 2.92}\n",
            "{'loss': 2.756, 'grad_norm': 1.3369457721710205, 'learning_rate': 0.0003267444444444445, 'epoch': 2.93}\n",
            "{'loss': 2.7685, 'grad_norm': 1.3212546110153198, 'learning_rate': 0.00032618888888888886, 'epoch': 2.93}\n",
            "{'loss': 2.7564, 'grad_norm': 1.4174741506576538, 'learning_rate': 0.00032564444444444445, 'epoch': 2.94}\n",
            "{'loss': 2.7619, 'grad_norm': 1.4804335832595825, 'learning_rate': 0.0003250888888888889, 'epoch': 2.95}\n",
            "{'loss': 2.7611, 'grad_norm': 1.394515872001648, 'learning_rate': 0.0003245333333333333, 'epoch': 2.96}\n",
            "{'loss': 2.7673, 'grad_norm': 1.3555235862731934, 'learning_rate': 0.00032397777777777776, 'epoch': 2.96}\n",
            "{'loss': 2.7426, 'grad_norm': 1.3086249828338623, 'learning_rate': 0.00032342222222222225, 'epoch': 2.97}\n",
            "{'loss': 2.7561, 'grad_norm': 1.3426563739776611, 'learning_rate': 0.0003228666666666667, 'epoch': 2.98}\n",
            "{'loss': 2.7674, 'grad_norm': 1.3249622583389282, 'learning_rate': 0.00032231111111111113, 'epoch': 2.98}\n",
            "{'loss': 2.7504, 'grad_norm': 1.302243947982788, 'learning_rate': 0.00032175555555555556, 'epoch': 2.99}\n",
            "{'loss': 2.7473, 'grad_norm': 1.272247314453125, 'learning_rate': 0.0003212, 'epoch': 3.0}\n",
            "{'loss': 2.7147, 'grad_norm': 1.4387495517730713, 'learning_rate': 0.00032064444444444444, 'epoch': 3.01}\n",
            "{'loss': 2.7223, 'grad_norm': 1.4292412996292114, 'learning_rate': 0.0003200888888888889, 'epoch': 3.01}\n",
            "{'loss': 2.7201, 'grad_norm': 1.3091099262237549, 'learning_rate': 0.00031953333333333337, 'epoch': 3.02}\n",
            "{'loss': 2.7461, 'grad_norm': 1.2836298942565918, 'learning_rate': 0.0003189777777777778, 'epoch': 3.03}\n",
            "{'loss': 2.7451, 'grad_norm': 1.387805700302124, 'learning_rate': 0.00031842222222222224, 'epoch': 3.03}\n",
            "{'loss': 2.7439, 'grad_norm': 1.3205647468566895, 'learning_rate': 0.0003178666666666667, 'epoch': 3.04}\n",
            "{'loss': 2.7531, 'grad_norm': 1.3593149185180664, 'learning_rate': 0.0003173111111111111, 'epoch': 3.05}\n",
            "{'loss': 2.7061, 'grad_norm': 1.3523684740066528, 'learning_rate': 0.00031675555555555555, 'epoch': 3.06}\n",
            "{'loss': 2.726, 'grad_norm': 1.3880733251571655, 'learning_rate': 0.0003162, 'epoch': 3.06}\n",
            "{'loss': 2.7202, 'grad_norm': 1.3103123903274536, 'learning_rate': 0.0003156444444444445, 'epoch': 3.07}\n",
            "{'loss': 2.7397, 'grad_norm': 1.3460437059402466, 'learning_rate': 0.00031508888888888886, 'epoch': 3.08}\n",
            "{'loss': 2.7417, 'grad_norm': 1.3029273748397827, 'learning_rate': 0.00031453333333333335, 'epoch': 3.08}\n",
            "{'loss': 2.6992, 'grad_norm': 1.3975939750671387, 'learning_rate': 0.0003139777777777778, 'epoch': 3.09}\n",
            "{'loss': 2.7217, 'grad_norm': 1.3717809915542603, 'learning_rate': 0.0003134222222222222, 'epoch': 3.1}\n",
            "{'loss': 2.7551, 'grad_norm': 1.3831998109817505, 'learning_rate': 0.00031286666666666666, 'epoch': 3.11}\n",
            "{'loss': 2.7102, 'grad_norm': 1.3424184322357178, 'learning_rate': 0.0003123111111111111, 'epoch': 3.11}\n",
            "{'loss': 2.7058, 'grad_norm': 1.2232911586761475, 'learning_rate': 0.0003117555555555556, 'epoch': 3.12}\n",
            "{'loss': 2.7418, 'grad_norm': 1.325195550918579, 'learning_rate': 0.0003112, 'epoch': 3.13}\n",
            " 44% 22000/50000 [33:44<41:59, 11.11it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 47.08it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 45.00it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.19it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.10it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 30.20it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.65it/s]\u001b[A\n",
            " 56% 33/59 [00:01<00:01, 23.56it/s]\u001b[A\n",
            " 61% 36/59 [00:01<00:01, 22.00it/s]\u001b[A\n",
            " 66% 39/59 [00:01<00:01, 19.96it/s]\u001b[A\n",
            " 71% 42/59 [00:01<00:00, 19.42it/s]\u001b[A\n",
            " 76% 45/59 [00:01<00:00, 19.09it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 18.97it/s]\u001b[A\n",
            " 83% 49/59 [00:02<00:00, 19.07it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.59it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.48it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.40it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.653010368347168, 'eval_accuracy': 0.5315396785736084, 'eval_runtime': 2.8655, 'eval_samples_per_second': 1312.15, 'eval_steps_per_second': 20.59, 'epoch': 3.13}\n",
            " 44% 22000/50000 [33:47<41:59, 11.11it/s]\n",
            "100% 59/59 [00:02<00:00, 19.60it/s]\u001b[A\n",
            "{'loss': 2.7211, 'grad_norm': 1.3330631256103516, 'learning_rate': 0.00031064444444444447, 'epoch': 3.13}\n",
            "{'loss': 2.7023, 'grad_norm': 1.2517235279083252, 'learning_rate': 0.0003100888888888889, 'epoch': 3.14}\n",
            "{'loss': 2.7168, 'grad_norm': 1.3409337997436523, 'learning_rate': 0.00030953333333333334, 'epoch': 3.15}\n",
            "{'loss': 2.7226, 'grad_norm': 1.3570001125335693, 'learning_rate': 0.0003089777777777778, 'epoch': 3.15}\n",
            "{'loss': 2.7225, 'grad_norm': 1.3122739791870117, 'learning_rate': 0.0003084222222222222, 'epoch': 3.16}\n",
            "{'loss': 2.7167, 'grad_norm': 1.4316604137420654, 'learning_rate': 0.0003078666666666667, 'epoch': 3.17}\n",
            "{'loss': 2.7217, 'grad_norm': 1.3182547092437744, 'learning_rate': 0.0003073111111111111, 'epoch': 3.18}\n",
            "{'loss': 2.7093, 'grad_norm': 1.3293880224227905, 'learning_rate': 0.0003067555555555556, 'epoch': 3.18}\n",
            "{'loss': 2.7193, 'grad_norm': 1.2502381801605225, 'learning_rate': 0.0003062, 'epoch': 3.19}\n",
            "{'loss': 2.7206, 'grad_norm': 1.3578076362609863, 'learning_rate': 0.00030564444444444445, 'epoch': 3.2}\n",
            "{'loss': 2.7173, 'grad_norm': 1.3825010061264038, 'learning_rate': 0.0003050888888888889, 'epoch': 3.2}\n",
            "{'loss': 2.6984, 'grad_norm': 1.2990226745605469, 'learning_rate': 0.0003045333333333333, 'epoch': 3.21}\n",
            "{'loss': 2.7011, 'grad_norm': 1.305288553237915, 'learning_rate': 0.0003039777777777778, 'epoch': 3.22}\n",
            "{'loss': 2.7018, 'grad_norm': 1.304976463317871, 'learning_rate': 0.00030343333333333335, 'epoch': 3.23}\n",
            "{'loss': 2.7058, 'grad_norm': 1.4142847061157227, 'learning_rate': 0.0003028777777777778, 'epoch': 3.23}\n",
            "{'loss': 2.6942, 'grad_norm': 1.312675952911377, 'learning_rate': 0.00030232222222222223, 'epoch': 3.24}\n",
            "{'loss': 2.7127, 'grad_norm': 1.2716552019119263, 'learning_rate': 0.00030176666666666667, 'epoch': 3.25}\n",
            "{'loss': 2.7015, 'grad_norm': 1.32575261592865, 'learning_rate': 0.0003012111111111111, 'epoch': 3.25}\n",
            "{'loss': 2.7031, 'grad_norm': 1.3190040588378906, 'learning_rate': 0.0003006555555555556, 'epoch': 3.26}\n",
            "{'loss': 2.7067, 'grad_norm': 1.4059545993804932, 'learning_rate': 0.0003001, 'epoch': 3.27}\n",
            "{'loss': 2.6921, 'grad_norm': 1.238997220993042, 'learning_rate': 0.00029954444444444447, 'epoch': 3.28}\n",
            "{'loss': 2.7104, 'grad_norm': 1.3806432485580444, 'learning_rate': 0.0002989888888888889, 'epoch': 3.28}\n",
            "{'loss': 2.6934, 'grad_norm': 1.3120543956756592, 'learning_rate': 0.00029843333333333334, 'epoch': 3.29}\n",
            "{'loss': 2.6758, 'grad_norm': 1.3114160299301147, 'learning_rate': 0.0002978777777777778, 'epoch': 3.3}\n",
            "{'loss': 2.6956, 'grad_norm': 1.3164069652557373, 'learning_rate': 0.0002973222222222222, 'epoch': 3.3}\n",
            "{'loss': 2.6863, 'grad_norm': 1.3632599115371704, 'learning_rate': 0.0002967666666666667, 'epoch': 3.31}\n",
            "{'loss': 2.7148, 'grad_norm': 1.434722661972046, 'learning_rate': 0.0002962111111111111, 'epoch': 3.32}\n",
            "{'loss': 2.6753, 'grad_norm': 1.2440563440322876, 'learning_rate': 0.0002956555555555556, 'epoch': 3.33}\n",
            "{'loss': 2.6789, 'grad_norm': 1.2840094566345215, 'learning_rate': 0.00029509999999999996, 'epoch': 3.33}\n",
            "{'loss': 2.702, 'grad_norm': 1.3208978176116943, 'learning_rate': 0.00029454444444444445, 'epoch': 3.34}\n",
            "{'loss': 2.6828, 'grad_norm': 1.398094892501831, 'learning_rate': 0.0002939888888888889, 'epoch': 3.35}\n",
            "{'loss': 2.6958, 'grad_norm': 1.4610600471496582, 'learning_rate': 0.00029343333333333333, 'epoch': 3.35}\n",
            "{'loss': 2.6976, 'grad_norm': 1.4085105657577515, 'learning_rate': 0.0002928777777777778, 'epoch': 3.36}\n",
            "{'loss': 2.6875, 'grad_norm': 1.346925973892212, 'learning_rate': 0.0002923222222222222, 'epoch': 3.37}\n",
            "{'loss': 2.6922, 'grad_norm': 1.3651189804077148, 'learning_rate': 0.0002917666666666667, 'epoch': 3.38}\n",
            "{'loss': 2.7099, 'grad_norm': 1.376969337463379, 'learning_rate': 0.0002912111111111111, 'epoch': 3.38}\n",
            "{'loss': 2.6997, 'grad_norm': 1.3373252153396606, 'learning_rate': 0.00029065555555555557, 'epoch': 3.39}\n",
            "{'loss': 2.6899, 'grad_norm': 1.2495291233062744, 'learning_rate': 0.0002901, 'epoch': 3.4}\n",
            "{'loss': 2.6684, 'grad_norm': 1.2818810939788818, 'learning_rate': 0.00028954444444444444, 'epoch': 3.4}\n",
            "{'loss': 2.6695, 'grad_norm': 1.3983908891677856, 'learning_rate': 0.00028898888888888893, 'epoch': 3.41}\n",
            " 48% 24000/50000 [36:48<38:57, 11.12it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 42.57it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 42.70it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 42.17it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.51it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.91it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.67it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 24.00it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.28it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.02it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.12it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.64it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.23it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 18.95it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.85it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.67it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.54it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.41it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.636086940765381, 'eval_accuracy': 0.5322381854057312, 'eval_runtime': 2.8823, 'eval_samples_per_second': 1304.51, 'eval_steps_per_second': 20.47, 'epoch': 3.41}\n",
            " 48% 24000/50000 [36:51<38:57, 11.12it/s]\n",
            "100% 59/59 [00:02<00:00, 17.65it/s]\u001b[A\n",
            "{'loss': 2.695, 'grad_norm': 1.3231110572814941, 'learning_rate': 0.0002884333333333333, 'epoch': 3.42}\n",
            "{'loss': 2.6501, 'grad_norm': 1.3818906545639038, 'learning_rate': 0.0002878777777777778, 'epoch': 3.42}\n",
            "{'loss': 2.6767, 'grad_norm': 1.2730073928833008, 'learning_rate': 0.0002873222222222222, 'epoch': 3.43}\n",
            "{'loss': 2.6821, 'grad_norm': 1.34419584274292, 'learning_rate': 0.0002867666666666667, 'epoch': 3.44}\n",
            "{'loss': 2.6805, 'grad_norm': 1.477826714515686, 'learning_rate': 0.00028621111111111117, 'epoch': 3.45}\n",
            "{'loss': 2.6825, 'grad_norm': 1.3269299268722534, 'learning_rate': 0.00028565555555555555, 'epoch': 3.45}\n",
            "{'loss': 2.6675, 'grad_norm': 1.3281221389770508, 'learning_rate': 0.00028510000000000005, 'epoch': 3.46}\n",
            "{'loss': 2.678, 'grad_norm': 1.3405601978302002, 'learning_rate': 0.00028454444444444443, 'epoch': 3.47}\n",
            "{'loss': 2.6724, 'grad_norm': 1.3261350393295288, 'learning_rate': 0.0002839888888888889, 'epoch': 3.47}\n",
            "{'loss': 2.6704, 'grad_norm': 1.3000210523605347, 'learning_rate': 0.0002834333333333333, 'epoch': 3.48}\n",
            "{'loss': 2.6799, 'grad_norm': 1.522412657737732, 'learning_rate': 0.0002828777777777778, 'epoch': 3.49}\n",
            "{'loss': 2.6775, 'grad_norm': 1.33955717086792, 'learning_rate': 0.0002823222222222222, 'epoch': 3.5}\n",
            "{'loss': 2.7071, 'grad_norm': 1.4042268991470337, 'learning_rate': 0.00028176666666666667, 'epoch': 3.5}\n",
            "{'loss': 2.66, 'grad_norm': 1.479781150817871, 'learning_rate': 0.00028121111111111116, 'epoch': 3.51}\n",
            "{'loss': 2.6684, 'grad_norm': 1.3505644798278809, 'learning_rate': 0.0002806666666666667, 'epoch': 3.52}\n",
            "{'loss': 2.693, 'grad_norm': 1.3392908573150635, 'learning_rate': 0.0002801111111111111, 'epoch': 3.52}\n",
            "{'loss': 2.6803, 'grad_norm': 1.3515141010284424, 'learning_rate': 0.00027955555555555557, 'epoch': 3.53}\n",
            "{'loss': 2.6746, 'grad_norm': 1.313320517539978, 'learning_rate': 0.000279, 'epoch': 3.54}\n",
            "{'loss': 2.6611, 'grad_norm': 1.3591188192367554, 'learning_rate': 0.00027844444444444444, 'epoch': 3.55}\n",
            "{'loss': 2.6778, 'grad_norm': 1.3309400081634521, 'learning_rate': 0.00027788888888888893, 'epoch': 3.55}\n",
            "{'loss': 2.6555, 'grad_norm': 1.3085771799087524, 'learning_rate': 0.0002773333333333333, 'epoch': 3.56}\n",
            "{'loss': 2.6603, 'grad_norm': 1.33302903175354, 'learning_rate': 0.0002767777777777778, 'epoch': 3.57}\n",
            "{'loss': 2.646, 'grad_norm': 1.2799502611160278, 'learning_rate': 0.0002762222222222222, 'epoch': 3.57}\n",
            "{'loss': 2.6644, 'grad_norm': 1.4174857139587402, 'learning_rate': 0.0002756666666666667, 'epoch': 3.58}\n",
            "{'loss': 2.6519, 'grad_norm': 1.35043203830719, 'learning_rate': 0.00027511111111111106, 'epoch': 3.59}\n",
            "{'loss': 2.6781, 'grad_norm': 1.3336431980133057, 'learning_rate': 0.00027455555555555556, 'epoch': 3.6}\n",
            "{'loss': 2.6659, 'grad_norm': 1.2406474351882935, 'learning_rate': 0.00027400000000000005, 'epoch': 3.6}\n",
            "{'loss': 2.6635, 'grad_norm': 1.3676735162734985, 'learning_rate': 0.00027344444444444443, 'epoch': 3.61}\n",
            "{'loss': 2.646, 'grad_norm': 1.3326785564422607, 'learning_rate': 0.0002728888888888889, 'epoch': 3.62}\n",
            "{'loss': 2.6676, 'grad_norm': 1.3219151496887207, 'learning_rate': 0.0002723333333333333, 'epoch': 3.62}\n",
            "{'loss': 2.6604, 'grad_norm': 1.399395227432251, 'learning_rate': 0.0002717777777777778, 'epoch': 3.63}\n",
            "{'loss': 2.6717, 'grad_norm': 1.181457757949829, 'learning_rate': 0.0002712222222222222, 'epoch': 3.64}\n",
            "{'loss': 2.6533, 'grad_norm': 1.4481422901153564, 'learning_rate': 0.00027066666666666667, 'epoch': 3.65}\n",
            "{'loss': 2.6612, 'grad_norm': 1.400527000427246, 'learning_rate': 0.00027011111111111116, 'epoch': 3.65}\n",
            "{'loss': 2.6387, 'grad_norm': 1.3148730993270874, 'learning_rate': 0.00026955555555555554, 'epoch': 3.66}\n",
            "{'loss': 2.654, 'grad_norm': 1.2811923027038574, 'learning_rate': 0.00026900000000000003, 'epoch': 3.67}\n",
            "{'loss': 2.6377, 'grad_norm': 1.343153953552246, 'learning_rate': 0.0002684444444444444, 'epoch': 3.67}\n",
            "{'loss': 2.634, 'grad_norm': 1.2370487451553345, 'learning_rate': 0.0002678888888888889, 'epoch': 3.68}\n",
            "{'loss': 2.6615, 'grad_norm': 1.2833560705184937, 'learning_rate': 0.00026733333333333334, 'epoch': 3.69}\n",
            "{'loss': 2.6408, 'grad_norm': 1.2724497318267822, 'learning_rate': 0.0002667777777777778, 'epoch': 3.69}\n",
            " 52% 26000/50000 [39:52<36:02, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 43.05it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.74it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.60it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.87it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.72it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.61it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 25.20it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.99it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.48it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.74it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.04it/s]\u001b[A\n",
            " 78% 46/59 [00:01<00:00, 18.89it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.78it/s]\u001b[A\n",
            " 88% 52/59 [00:02<00:00, 19.26it/s]\u001b[A\n",
            " 92% 54/59 [00:02<00:00, 19.04it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.86it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.661454677581787, 'eval_accuracy': 0.5272795557975769, 'eval_runtime': 2.9104, 'eval_samples_per_second': 1291.932, 'eval_steps_per_second': 20.272, 'epoch': 3.69}\n",
            " 52% 26000/50000 [39:55<36:02, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 18.69it/s]\u001b[A\n",
            "{'loss': 2.638, 'grad_norm': 1.41643226146698, 'learning_rate': 0.00026622222222222227, 'epoch': 3.7}\n",
            "{'loss': 2.637, 'grad_norm': 1.4214186668395996, 'learning_rate': 0.00026566666666666666, 'epoch': 3.71}\n",
            "{'loss': 2.6359, 'grad_norm': 1.300740122795105, 'learning_rate': 0.00026511111111111115, 'epoch': 3.72}\n",
            "{'loss': 2.6487, 'grad_norm': 1.316301703453064, 'learning_rate': 0.00026455555555555553, 'epoch': 3.72}\n",
            "{'loss': 2.6503, 'grad_norm': 1.2592027187347412, 'learning_rate': 0.000264, 'epoch': 3.73}\n",
            "{'loss': 2.6422, 'grad_norm': 1.378704309463501, 'learning_rate': 0.00026344444444444446, 'epoch': 3.74}\n",
            "{'loss': 2.6499, 'grad_norm': 1.4038299322128296, 'learning_rate': 0.0002628888888888889, 'epoch': 3.74}\n",
            "{'loss': 2.6106, 'grad_norm': 1.4126653671264648, 'learning_rate': 0.00026233333333333333, 'epoch': 3.75}\n",
            "{'loss': 2.6236, 'grad_norm': 1.2411243915557861, 'learning_rate': 0.00026177777777777777, 'epoch': 3.76}\n",
            "{'loss': 2.6303, 'grad_norm': 1.455971121788025, 'learning_rate': 0.00026122222222222226, 'epoch': 3.77}\n",
            "{'loss': 2.6321, 'grad_norm': 1.3411461114883423, 'learning_rate': 0.00026066666666666664, 'epoch': 3.77}\n",
            "{'loss': 2.6489, 'grad_norm': 1.4417579174041748, 'learning_rate': 0.00026011111111111113, 'epoch': 3.78}\n",
            "{'loss': 2.6341, 'grad_norm': 1.3618847131729126, 'learning_rate': 0.00025955555555555557, 'epoch': 3.79}\n",
            "{'loss': 2.6534, 'grad_norm': 1.3875294923782349, 'learning_rate': 0.000259, 'epoch': 3.79}\n",
            "{'loss': 2.6296, 'grad_norm': 1.2789055109024048, 'learning_rate': 0.00025845555555555554, 'epoch': 3.8}\n",
            "{'loss': 2.6011, 'grad_norm': 1.4122520685195923, 'learning_rate': 0.00025790000000000003, 'epoch': 3.81}\n",
            "{'loss': 2.6309, 'grad_norm': 1.3911676406860352, 'learning_rate': 0.0002573444444444444, 'epoch': 3.82}\n",
            "{'loss': 2.6292, 'grad_norm': 1.323366641998291, 'learning_rate': 0.0002567888888888889, 'epoch': 3.82}\n",
            "{'loss': 2.6233, 'grad_norm': 1.3632664680480957, 'learning_rate': 0.0002562333333333333, 'epoch': 3.83}\n",
            "{'loss': 2.6171, 'grad_norm': 1.2877609729766846, 'learning_rate': 0.0002556777777777778, 'epoch': 3.84}\n",
            "{'loss': 2.6168, 'grad_norm': 1.4089664220809937, 'learning_rate': 0.0002551222222222222, 'epoch': 3.84}\n",
            "{'loss': 2.6376, 'grad_norm': 1.4261869192123413, 'learning_rate': 0.00025456666666666666, 'epoch': 3.85}\n",
            "{'loss': 2.642, 'grad_norm': 1.3045943975448608, 'learning_rate': 0.00025401111111111115, 'epoch': 3.86}\n",
            "{'loss': 2.6362, 'grad_norm': 1.392120122909546, 'learning_rate': 0.00025345555555555553, 'epoch': 3.87}\n",
            "{'loss': 2.6217, 'grad_norm': 1.2576981782913208, 'learning_rate': 0.0002529, 'epoch': 3.87}\n",
            "{'loss': 2.6234, 'grad_norm': 1.4041427373886108, 'learning_rate': 0.00025234444444444446, 'epoch': 3.88}\n",
            "{'loss': 2.6239, 'grad_norm': 1.469545841217041, 'learning_rate': 0.0002517888888888889, 'epoch': 3.89}\n",
            "{'loss': 2.6155, 'grad_norm': 1.354499340057373, 'learning_rate': 0.00025123333333333333, 'epoch': 3.89}\n",
            "{'loss': 2.6153, 'grad_norm': 1.3765227794647217, 'learning_rate': 0.00025067777777777777, 'epoch': 3.9}\n",
            "{'loss': 2.6303, 'grad_norm': 1.2957273721694946, 'learning_rate': 0.00025012222222222226, 'epoch': 3.91}\n",
            "{'loss': 2.6316, 'grad_norm': 1.3341894149780273, 'learning_rate': 0.00024956666666666664, 'epoch': 3.92}\n",
            "{'loss': 2.6003, 'grad_norm': 1.3402856588363647, 'learning_rate': 0.0002490111111111111, 'epoch': 3.92}\n",
            "{'loss': 2.6195, 'grad_norm': 1.4495972394943237, 'learning_rate': 0.00024845555555555557, 'epoch': 3.93}\n",
            "{'loss': 2.6633, 'grad_norm': 1.2781521081924438, 'learning_rate': 0.0002479, 'epoch': 3.94}\n",
            "{'loss': 2.6002, 'grad_norm': 1.3943521976470947, 'learning_rate': 0.00024734444444444445, 'epoch': 3.94}\n",
            "{'loss': 2.6106, 'grad_norm': 1.378824234008789, 'learning_rate': 0.0002467888888888889, 'epoch': 3.95}\n",
            "{'loss': 2.6227, 'grad_norm': 1.3672019243240356, 'learning_rate': 0.0002462333333333333, 'epoch': 3.96}\n",
            "{'loss': 2.6121, 'grad_norm': 1.3261276483535767, 'learning_rate': 0.00024567777777777776, 'epoch': 3.96}\n",
            "{'loss': 2.6274, 'grad_norm': 1.2889728546142578, 'learning_rate': 0.0002451222222222222, 'epoch': 3.97}\n",
            "{'loss': 2.6139, 'grad_norm': 1.3193587064743042, 'learning_rate': 0.0002445666666666667, 'epoch': 3.98}\n",
            " 56% 28000/50000 [42:56<33:03, 11.09it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 41.70it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 40.09it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 40.79it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 39.76it/s]\u001b[A\n",
            " 41% 24/59 [00:00<00:00, 36.33it/s]\u001b[A\n",
            " 47% 28/59 [00:00<00:01, 27.86it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.96it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.22it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.09it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.17it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.61it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.25it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.01it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.81it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.65it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.62it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.49it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.596156597137451, 'eval_accuracy': 0.5412070155143738, 'eval_runtime': 2.8558, 'eval_samples_per_second': 1316.624, 'eval_steps_per_second': 20.66, 'epoch': 3.98}\n",
            " 56% 28000/50000 [42:59<33:03, 11.09it/s]\n",
            "100% 59/59 [00:02<00:00, 17.63it/s]\u001b[A\n",
            "{'loss': 2.6081, 'grad_norm': 1.4086081981658936, 'learning_rate': 0.00024401111111111112, 'epoch': 3.99}\n",
            "{'loss': 2.6323, 'grad_norm': 1.4046396017074585, 'learning_rate': 0.00024345555555555556, 'epoch': 3.99}\n",
            "{'loss': 2.6022, 'grad_norm': 1.3317283391952515, 'learning_rate': 0.00024290000000000002, 'epoch': 4.0}\n",
            "{'loss': 2.5847, 'grad_norm': 1.2647290229797363, 'learning_rate': 0.00024234444444444446, 'epoch': 4.01}\n",
            "{'loss': 2.5759, 'grad_norm': 1.3554668426513672, 'learning_rate': 0.0002417888888888889, 'epoch': 4.01}\n",
            "{'loss': 2.5941, 'grad_norm': 1.433657169342041, 'learning_rate': 0.00024123333333333333, 'epoch': 4.02}\n",
            "{'loss': 2.6103, 'grad_norm': 1.3923662900924683, 'learning_rate': 0.00024067777777777777, 'epoch': 4.03}\n",
            "{'loss': 2.5886, 'grad_norm': 1.513284683227539, 'learning_rate': 0.0002401222222222222, 'epoch': 4.04}\n",
            "{'loss': 2.5792, 'grad_norm': 1.2901095151901245, 'learning_rate': 0.00023956666666666667, 'epoch': 4.04}\n",
            "{'loss': 2.5752, 'grad_norm': 1.2577502727508545, 'learning_rate': 0.00023901111111111114, 'epoch': 4.05}\n",
            "{'loss': 2.5888, 'grad_norm': 1.3110523223876953, 'learning_rate': 0.00023845555555555557, 'epoch': 4.06}\n",
            "{'loss': 2.5783, 'grad_norm': 1.4693686962127686, 'learning_rate': 0.0002379, 'epoch': 4.06}\n",
            "{'loss': 2.6093, 'grad_norm': 1.3847119808197021, 'learning_rate': 0.00023734444444444445, 'epoch': 4.07}\n",
            "{'loss': 2.598, 'grad_norm': 1.28691828250885, 'learning_rate': 0.00023678888888888888, 'epoch': 4.08}\n",
            "{'loss': 2.5989, 'grad_norm': 1.3743922710418701, 'learning_rate': 0.00023624444444444445, 'epoch': 4.09}\n",
            "{'loss': 2.5904, 'grad_norm': 1.2893030643463135, 'learning_rate': 0.0002356888888888889, 'epoch': 4.09}\n",
            "{'loss': 2.5571, 'grad_norm': 1.3981425762176514, 'learning_rate': 0.00023513333333333335, 'epoch': 4.1}\n",
            "{'loss': 2.5629, 'grad_norm': 1.4046043157577515, 'learning_rate': 0.00023457777777777778, 'epoch': 4.11}\n",
            "{'loss': 2.596, 'grad_norm': 1.5157936811447144, 'learning_rate': 0.00023402222222222222, 'epoch': 4.11}\n",
            "{'loss': 2.5762, 'grad_norm': 1.4160593748092651, 'learning_rate': 0.00023346666666666666, 'epoch': 4.12}\n",
            "{'loss': 2.5805, 'grad_norm': 1.4395025968551636, 'learning_rate': 0.00023291111111111112, 'epoch': 4.13}\n",
            "{'loss': 2.5753, 'grad_norm': 1.4099695682525635, 'learning_rate': 0.00023235555555555556, 'epoch': 4.14}\n",
            "{'loss': 2.5875, 'grad_norm': 1.2923104763031006, 'learning_rate': 0.00023180000000000002, 'epoch': 4.14}\n",
            "{'loss': 2.5702, 'grad_norm': 1.3500428199768066, 'learning_rate': 0.00023124444444444446, 'epoch': 4.15}\n",
            "{'loss': 2.5718, 'grad_norm': 1.338653326034546, 'learning_rate': 0.0002306888888888889, 'epoch': 4.16}\n",
            "{'loss': 2.5732, 'grad_norm': 1.3077569007873535, 'learning_rate': 0.00023013333333333333, 'epoch': 4.16}\n",
            "{'loss': 2.5751, 'grad_norm': 1.3431048393249512, 'learning_rate': 0.00022957777777777777, 'epoch': 4.17}\n",
            "{'loss': 2.593, 'grad_norm': 1.4396066665649414, 'learning_rate': 0.0002290222222222222, 'epoch': 4.18}\n",
            "{'loss': 2.6055, 'grad_norm': 1.3048368692398071, 'learning_rate': 0.00022846666666666667, 'epoch': 4.19}\n",
            "{'loss': 2.5867, 'grad_norm': 1.367199420928955, 'learning_rate': 0.00022791111111111114, 'epoch': 4.19}\n",
            "{'loss': 2.5626, 'grad_norm': 1.343048334121704, 'learning_rate': 0.00022735555555555557, 'epoch': 4.2}\n",
            "{'loss': 2.5877, 'grad_norm': 1.3110847473144531, 'learning_rate': 0.0002268, 'epoch': 4.21}\n",
            "{'loss': 2.5524, 'grad_norm': 1.309981107711792, 'learning_rate': 0.00022624444444444445, 'epoch': 4.21}\n",
            "{'loss': 2.5826, 'grad_norm': 1.3832635879516602, 'learning_rate': 0.00022568888888888888, 'epoch': 4.22}\n",
            "{'loss': 2.5919, 'grad_norm': 1.3432589769363403, 'learning_rate': 0.00022513333333333332, 'epoch': 4.23}\n",
            "{'loss': 2.5915, 'grad_norm': 1.4046261310577393, 'learning_rate': 0.00022457777777777776, 'epoch': 4.23}\n",
            "{'loss': 2.5489, 'grad_norm': 1.3556199073791504, 'learning_rate': 0.00022402222222222225, 'epoch': 4.24}\n",
            "{'loss': 2.5625, 'grad_norm': 1.3245574235916138, 'learning_rate': 0.0002234666666666667, 'epoch': 4.25}\n",
            "{'loss': 2.5682, 'grad_norm': 1.3008946180343628, 'learning_rate': 0.00022291111111111112, 'epoch': 4.26}\n",
            "{'loss': 2.5719, 'grad_norm': 1.286606788635254, 'learning_rate': 0.00022235555555555556, 'epoch': 4.26}\n",
            " 60% 30000/50000 [46:01<30:00, 11.11it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.75it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.70it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.25it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.01it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.57it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 27.16it/s]\u001b[A\n",
            " 56% 33/59 [00:01<00:01, 23.76it/s]\u001b[A\n",
            " 61% 36/59 [00:01<00:01, 22.17it/s]\u001b[A\n",
            " 66% 39/59 [00:01<00:01, 20.00it/s]\u001b[A\n",
            " 71% 42/59 [00:01<00:00, 19.48it/s]\u001b[A\n",
            " 76% 45/59 [00:01<00:00, 19.13it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 18.05it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 20.14it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.57it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 19.13it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.5255143642425537, 'eval_accuracy': 0.5484740734100342, 'eval_runtime': 2.8492, 'eval_samples_per_second': 1319.685, 'eval_steps_per_second': 20.708, 'epoch': 4.26}\n",
            " 60% 30000/50000 [46:04<30:00, 11.11it/s]\n",
            "100% 59/59 [00:02<00:00, 18.91it/s]\u001b[A\n",
            "{'loss': 2.5442, 'grad_norm': 1.301270604133606, 'learning_rate': 0.0002218, 'epoch': 4.27}\n",
            "{'loss': 2.5567, 'grad_norm': 1.3700851202011108, 'learning_rate': 0.00022124444444444443, 'epoch': 4.28}\n",
            "{'loss': 2.5789, 'grad_norm': 1.392661690711975, 'learning_rate': 0.00022068888888888887, 'epoch': 4.28}\n",
            "{'loss': 2.5511, 'grad_norm': 1.3323793411254883, 'learning_rate': 0.00022013333333333334, 'epoch': 4.29}\n",
            "{'loss': 2.5674, 'grad_norm': 1.3777954578399658, 'learning_rate': 0.0002195777777777778, 'epoch': 4.3}\n",
            "{'loss': 2.5656, 'grad_norm': 1.449472188949585, 'learning_rate': 0.00021902222222222224, 'epoch': 4.31}\n",
            "{'loss': 2.5601, 'grad_norm': 1.4954051971435547, 'learning_rate': 0.00021846666666666667, 'epoch': 4.31}\n",
            "{'loss': 2.5344, 'grad_norm': 1.4802621603012085, 'learning_rate': 0.0002179111111111111, 'epoch': 4.32}\n",
            "{'loss': 2.5619, 'grad_norm': 1.3738172054290771, 'learning_rate': 0.00021735555555555555, 'epoch': 4.33}\n",
            "{'loss': 2.5746, 'grad_norm': 1.3755439519882202, 'learning_rate': 0.00021679999999999998, 'epoch': 4.33}\n",
            "{'loss': 2.566, 'grad_norm': 1.4675263166427612, 'learning_rate': 0.00021624444444444445, 'epoch': 4.34}\n",
            "{'loss': 2.5614, 'grad_norm': 1.3958425521850586, 'learning_rate': 0.0002156888888888889, 'epoch': 4.35}\n",
            "{'loss': 2.5801, 'grad_norm': 1.5395402908325195, 'learning_rate': 0.00021513333333333335, 'epoch': 4.36}\n",
            "{'loss': 2.5562, 'grad_norm': 1.2854769229888916, 'learning_rate': 0.00021457777777777779, 'epoch': 4.36}\n",
            "{'loss': 2.5469, 'grad_norm': 1.4327179193496704, 'learning_rate': 0.00021403333333333332, 'epoch': 4.37}\n",
            "{'loss': 2.5593, 'grad_norm': 1.3113369941711426, 'learning_rate': 0.00021347777777777776, 'epoch': 4.38}\n",
            "{'loss': 2.5538, 'grad_norm': 1.2494531869888306, 'learning_rate': 0.00021292222222222225, 'epoch': 4.38}\n",
            "{'loss': 2.5497, 'grad_norm': 1.3315054178237915, 'learning_rate': 0.0002123666666666667, 'epoch': 4.39}\n",
            "{'loss': 2.5762, 'grad_norm': 1.3972538709640503, 'learning_rate': 0.00021181111111111112, 'epoch': 4.4}\n",
            "{'loss': 2.5667, 'grad_norm': 1.313956618309021, 'learning_rate': 0.00021125555555555556, 'epoch': 4.41}\n",
            "{'loss': 2.5194, 'grad_norm': 1.3468201160430908, 'learning_rate': 0.0002107, 'epoch': 4.41}\n",
            "{'loss': 2.5667, 'grad_norm': 1.3583379983901978, 'learning_rate': 0.00021014444444444444, 'epoch': 4.42}\n",
            "{'loss': 2.5804, 'grad_norm': 1.3277928829193115, 'learning_rate': 0.00020958888888888887, 'epoch': 4.43}\n",
            "{'loss': 2.5549, 'grad_norm': 1.3497791290283203, 'learning_rate': 0.00020903333333333334, 'epoch': 4.43}\n",
            "{'loss': 2.5586, 'grad_norm': 1.337796926498413, 'learning_rate': 0.0002084777777777778, 'epoch': 4.44}\n",
            "{'loss': 2.5474, 'grad_norm': 1.3472398519515991, 'learning_rate': 0.00020792222222222224, 'epoch': 4.45}\n",
            "{'loss': 2.5761, 'grad_norm': 1.3806076049804688, 'learning_rate': 0.00020736666666666667, 'epoch': 4.46}\n",
            "{'loss': 2.5429, 'grad_norm': 1.3610293865203857, 'learning_rate': 0.0002068111111111111, 'epoch': 4.46}\n",
            "{'loss': 2.5544, 'grad_norm': 1.5134917497634888, 'learning_rate': 0.00020625555555555555, 'epoch': 4.47}\n",
            "{'loss': 2.5587, 'grad_norm': 1.4128586053848267, 'learning_rate': 0.00020569999999999999, 'epoch': 4.48}\n",
            "{'loss': 2.526, 'grad_norm': 1.4036728143692017, 'learning_rate': 0.00020514444444444445, 'epoch': 4.48}\n",
            "{'loss': 2.5401, 'grad_norm': 1.3635777235031128, 'learning_rate': 0.0002045888888888889, 'epoch': 4.49}\n",
            "{'loss': 2.5457, 'grad_norm': 1.4192839860916138, 'learning_rate': 0.00020403333333333335, 'epoch': 4.5}\n",
            "{'loss': 2.5678, 'grad_norm': 1.3779586553573608, 'learning_rate': 0.0002034777777777778, 'epoch': 4.5}\n",
            "{'loss': 2.5195, 'grad_norm': 1.3224438428878784, 'learning_rate': 0.00020292222222222222, 'epoch': 4.51}\n",
            "{'loss': 2.5668, 'grad_norm': 1.3311437368392944, 'learning_rate': 0.00020236666666666666, 'epoch': 4.52}\n",
            "{'loss': 2.5482, 'grad_norm': 1.3532224893569946, 'learning_rate': 0.0002018111111111111, 'epoch': 4.53}\n",
            "{'loss': 2.5382, 'grad_norm': 1.294075608253479, 'learning_rate': 0.00020125555555555556, 'epoch': 4.53}\n",
            "{'loss': 2.5507, 'grad_norm': 1.346355676651001, 'learning_rate': 0.0002007, 'epoch': 4.54}\n",
            "{'loss': 2.5349, 'grad_norm': 1.3900302648544312, 'learning_rate': 0.00020014444444444446, 'epoch': 4.55}\n",
            " 64% 32000/50000 [49:05<27:15, 11.01it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 45.84it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.33it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.82it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.66it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.10it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.28it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.85it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.06it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.91it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.12it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.61it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.17it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 18.99it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.79it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.63it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.51it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.47it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.5061182975769043, 'eval_accuracy': 0.5490589141845703, 'eval_runtime': 2.8719, 'eval_samples_per_second': 1309.225, 'eval_steps_per_second': 20.544, 'epoch': 4.55}\n",
            " 64% 32000/50000 [49:08<27:15, 11.01it/s]\n",
            "100% 59/59 [00:02<00:00, 17.68it/s]\u001b[A\n",
            "{'loss': 2.5428, 'grad_norm': 1.3911442756652832, 'learning_rate': 0.0001995888888888889, 'epoch': 4.55}\n",
            "{'loss': 2.5376, 'grad_norm': 1.4513537883758545, 'learning_rate': 0.00019903333333333334, 'epoch': 4.56}\n",
            "{'loss': 2.5513, 'grad_norm': 1.4372987747192383, 'learning_rate': 0.00019847777777777777, 'epoch': 4.57}\n",
            "{'loss': 2.5417, 'grad_norm': 1.4005707502365112, 'learning_rate': 0.00019792222222222224, 'epoch': 4.58}\n",
            "{'loss': 2.536, 'grad_norm': 1.3505767583847046, 'learning_rate': 0.00019736666666666668, 'epoch': 4.58}\n",
            "{'loss': 2.5375, 'grad_norm': 1.385550856590271, 'learning_rate': 0.0001968111111111111, 'epoch': 4.59}\n",
            "{'loss': 2.5398, 'grad_norm': 1.2861108779907227, 'learning_rate': 0.00019625555555555555, 'epoch': 4.6}\n",
            "{'loss': 2.5369, 'grad_norm': 1.369066834449768, 'learning_rate': 0.0001957, 'epoch': 4.6}\n",
            "{'loss': 2.5239, 'grad_norm': 1.4294403791427612, 'learning_rate': 0.00019514444444444445, 'epoch': 4.61}\n",
            "{'loss': 2.5356, 'grad_norm': 1.404035210609436, 'learning_rate': 0.0001945888888888889, 'epoch': 4.62}\n",
            "{'loss': 2.5511, 'grad_norm': 1.2899874448776245, 'learning_rate': 0.00019403333333333335, 'epoch': 4.63}\n",
            "{'loss': 2.526, 'grad_norm': 1.3604097366333008, 'learning_rate': 0.0001934777777777778, 'epoch': 4.63}\n",
            "{'loss': 2.5386, 'grad_norm': 1.3009285926818848, 'learning_rate': 0.00019292222222222223, 'epoch': 4.64}\n",
            "{'loss': 2.5389, 'grad_norm': 1.384542465209961, 'learning_rate': 0.00019236666666666666, 'epoch': 4.65}\n",
            "{'loss': 2.5472, 'grad_norm': 1.4813657999038696, 'learning_rate': 0.00019182222222222223, 'epoch': 4.65}\n",
            "{'loss': 2.5075, 'grad_norm': 1.409260869026184, 'learning_rate': 0.00019126666666666666, 'epoch': 4.66}\n",
            "{'loss': 2.534, 'grad_norm': 1.397831678390503, 'learning_rate': 0.0001907111111111111, 'epoch': 4.67}\n",
            "{'loss': 2.5204, 'grad_norm': 1.3630971908569336, 'learning_rate': 0.00019015555555555556, 'epoch': 4.68}\n",
            "{'loss': 2.5259, 'grad_norm': 1.5723048448562622, 'learning_rate': 0.0001896, 'epoch': 4.68}\n",
            "{'loss': 2.5383, 'grad_norm': 1.3775367736816406, 'learning_rate': 0.00018904444444444444, 'epoch': 4.69}\n",
            "{'loss': 2.5323, 'grad_norm': 1.3832205533981323, 'learning_rate': 0.0001884888888888889, 'epoch': 4.7}\n",
            "{'loss': 2.5454, 'grad_norm': 1.3337551355361938, 'learning_rate': 0.00018793333333333334, 'epoch': 4.7}\n",
            "{'loss': 2.5422, 'grad_norm': 1.4614602327346802, 'learning_rate': 0.00018737777777777778, 'epoch': 4.71}\n",
            "{'loss': 2.5352, 'grad_norm': 1.341331124305725, 'learning_rate': 0.00018682222222222224, 'epoch': 4.72}\n",
            "{'loss': 2.5408, 'grad_norm': 1.352297067642212, 'learning_rate': 0.00018626666666666668, 'epoch': 4.73}\n",
            "{'loss': 2.5218, 'grad_norm': 1.4738378524780273, 'learning_rate': 0.00018571111111111111, 'epoch': 4.73}\n",
            "{'loss': 2.5122, 'grad_norm': 1.3629697561264038, 'learning_rate': 0.00018515555555555555, 'epoch': 4.74}\n",
            "{'loss': 2.5182, 'grad_norm': 1.4276964664459229, 'learning_rate': 0.0001846, 'epoch': 4.75}\n",
            "{'loss': 2.534, 'grad_norm': 1.2839099168777466, 'learning_rate': 0.00018404444444444445, 'epoch': 4.75}\n",
            "{'loss': 2.5323, 'grad_norm': 1.328364610671997, 'learning_rate': 0.0001834888888888889, 'epoch': 4.76}\n",
            "{'loss': 2.5217, 'grad_norm': 1.4420113563537598, 'learning_rate': 0.00018293333333333335, 'epoch': 4.77}\n",
            "{'loss': 2.5101, 'grad_norm': 1.3917055130004883, 'learning_rate': 0.0001823777777777778, 'epoch': 4.77}\n",
            "{'loss': 2.5431, 'grad_norm': 1.3793225288391113, 'learning_rate': 0.00018182222222222223, 'epoch': 4.78}\n",
            "{'loss': 2.5085, 'grad_norm': 1.3956495523452759, 'learning_rate': 0.00018126666666666666, 'epoch': 4.79}\n",
            "{'loss': 2.5213, 'grad_norm': 1.349229335784912, 'learning_rate': 0.0001807111111111111, 'epoch': 4.8}\n",
            "{'loss': 2.4964, 'grad_norm': 1.2860863208770752, 'learning_rate': 0.00018015555555555556, 'epoch': 4.8}\n",
            "{'loss': 2.5242, 'grad_norm': 1.3014150857925415, 'learning_rate': 0.0001796, 'epoch': 4.81}\n",
            "{'loss': 2.5202, 'grad_norm': 1.3796244859695435, 'learning_rate': 0.00017904444444444447, 'epoch': 4.82}\n",
            "{'loss': 2.5308, 'grad_norm': 1.4026453495025635, 'learning_rate': 0.0001784888888888889, 'epoch': 4.82}\n",
            "{'loss': 2.5232, 'grad_norm': 1.339198350906372, 'learning_rate': 0.00017793333333333334, 'epoch': 4.83}\n",
            " 68% 34000/50000 [52:09<24:08, 11.05it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 42.60it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.54it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.67it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.56it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.37it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.41it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.89it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.25it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.92it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.17it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.56it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.18it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 18.96it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.81it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.65it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.57it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.45it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.4767065048217773, 'eval_accuracy': 0.5533403754234314, 'eval_runtime': 2.8607, 'eval_samples_per_second': 1314.366, 'eval_steps_per_second': 20.624, 'epoch': 4.83}\n",
            " 68% 34000/50000 [52:12<24:08, 11.05it/s]\n",
            "100% 59/59 [00:02<00:00, 17.57it/s]\u001b[A\n",
            "{'loss': 2.5258, 'grad_norm': 1.3102436065673828, 'learning_rate': 0.00017737777777777778, 'epoch': 4.84}\n",
            "{'loss': 2.5187, 'grad_norm': 1.3413504362106323, 'learning_rate': 0.0001768222222222222, 'epoch': 4.85}\n",
            "{'loss': 2.5207, 'grad_norm': 1.4840744733810425, 'learning_rate': 0.00017626666666666665, 'epoch': 4.85}\n",
            "{'loss': 2.5097, 'grad_norm': 1.3343290090560913, 'learning_rate': 0.00017571111111111111, 'epoch': 4.86}\n",
            "{'loss': 2.5037, 'grad_norm': 1.3177556991577148, 'learning_rate': 0.00017515555555555558, 'epoch': 4.87}\n",
            "{'loss': 2.4977, 'grad_norm': 1.467670202255249, 'learning_rate': 0.00017460000000000002, 'epoch': 4.87}\n",
            "{'loss': 2.5067, 'grad_norm': 1.37435781955719, 'learning_rate': 0.00017404444444444445, 'epoch': 4.88}\n",
            "{'loss': 2.5328, 'grad_norm': 1.39203941822052, 'learning_rate': 0.0001734888888888889, 'epoch': 4.89}\n",
            "{'loss': 2.508, 'grad_norm': 1.409658432006836, 'learning_rate': 0.00017293333333333333, 'epoch': 4.9}\n",
            "{'loss': 2.4979, 'grad_norm': 1.3622422218322754, 'learning_rate': 0.00017237777777777776, 'epoch': 4.9}\n",
            "{'loss': 2.506, 'grad_norm': 1.29069983959198, 'learning_rate': 0.0001718222222222222, 'epoch': 4.91}\n",
            "{'loss': 2.505, 'grad_norm': 1.3961434364318848, 'learning_rate': 0.0001712666666666667, 'epoch': 4.92}\n",
            "{'loss': 2.5013, 'grad_norm': 1.4365296363830566, 'learning_rate': 0.00017071111111111113, 'epoch': 4.92}\n",
            "{'loss': 2.4999, 'grad_norm': 1.3288507461547852, 'learning_rate': 0.00017015555555555557, 'epoch': 4.93}\n",
            "{'loss': 2.5165, 'grad_norm': 1.3913403749465942, 'learning_rate': 0.0001696111111111111, 'epoch': 4.94}\n",
            "{'loss': 2.4796, 'grad_norm': 1.3167730569839478, 'learning_rate': 0.00016905555555555554, 'epoch': 4.95}\n",
            "{'loss': 2.5219, 'grad_norm': 1.3867417573928833, 'learning_rate': 0.0001685, 'epoch': 4.95}\n",
            "{'loss': 2.4879, 'grad_norm': 1.4510455131530762, 'learning_rate': 0.00016794444444444447, 'epoch': 4.96}\n",
            "{'loss': 2.5219, 'grad_norm': 1.3686751127243042, 'learning_rate': 0.0001673888888888889, 'epoch': 4.97}\n",
            "{'loss': 2.5328, 'grad_norm': 1.3453501462936401, 'learning_rate': 0.00016683333333333334, 'epoch': 4.97}\n",
            "{'loss': 2.5115, 'grad_norm': 1.3086843490600586, 'learning_rate': 0.00016627777777777778, 'epoch': 4.98}\n",
            "{'loss': 2.4989, 'grad_norm': 1.3830310106277466, 'learning_rate': 0.00016572222222222221, 'epoch': 4.99}\n",
            "{'loss': 2.4895, 'grad_norm': 1.3455173969268799, 'learning_rate': 0.00016516666666666665, 'epoch': 5.0}\n",
            "{'loss': 2.5068, 'grad_norm': 1.454951286315918, 'learning_rate': 0.00016461111111111112, 'epoch': 5.0}\n",
            "{'loss': 2.472, 'grad_norm': 1.4321461915969849, 'learning_rate': 0.00016405555555555558, 'epoch': 5.01}\n",
            "{'loss': 2.4809, 'grad_norm': 1.3587782382965088, 'learning_rate': 0.00016350000000000002, 'epoch': 5.02}\n",
            "{'loss': 2.5021, 'grad_norm': 1.4085265398025513, 'learning_rate': 0.00016294444444444445, 'epoch': 5.02}\n",
            "{'loss': 2.4936, 'grad_norm': 1.371132731437683, 'learning_rate': 0.0001623888888888889, 'epoch': 5.03}\n",
            "{'loss': 2.4971, 'grad_norm': 1.3673917055130005, 'learning_rate': 0.00016183333333333333, 'epoch': 5.04}\n",
            "{'loss': 2.4901, 'grad_norm': 1.3829681873321533, 'learning_rate': 0.00016127777777777776, 'epoch': 5.04}\n",
            "{'loss': 2.452, 'grad_norm': 1.5632389783859253, 'learning_rate': 0.0001607222222222222, 'epoch': 5.05}\n",
            "{'loss': 2.4586, 'grad_norm': 1.3888065814971924, 'learning_rate': 0.0001601666666666667, 'epoch': 5.06}\n",
            "{'loss': 2.4825, 'grad_norm': 1.5184866189956665, 'learning_rate': 0.00015961111111111113, 'epoch': 5.07}\n",
            "{'loss': 2.4783, 'grad_norm': 1.461264729499817, 'learning_rate': 0.00015905555555555557, 'epoch': 5.07}\n",
            "{'loss': 2.4698, 'grad_norm': 1.3098807334899902, 'learning_rate': 0.0001585, 'epoch': 5.08}\n",
            "{'loss': 2.4971, 'grad_norm': 1.4262040853500366, 'learning_rate': 0.00015794444444444444, 'epoch': 5.09}\n",
            "{'loss': 2.4848, 'grad_norm': 1.3454533815383911, 'learning_rate': 0.00015738888888888888, 'epoch': 5.09}\n",
            "{'loss': 2.4809, 'grad_norm': 1.3702647686004639, 'learning_rate': 0.00015683333333333331, 'epoch': 5.1}\n",
            "{'loss': 2.48, 'grad_norm': 1.4843220710754395, 'learning_rate': 0.00015627777777777778, 'epoch': 5.11}\n",
            "{'loss': 2.4692, 'grad_norm': 1.345293402671814, 'learning_rate': 0.00015572222222222224, 'epoch': 5.12}\n",
            " 72% 36000/50000 [55:14<21:01, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 46.12it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.52it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.00it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 43.48it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.79it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.64it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 22.72it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.40it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.47it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.84it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 20.29it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 20.82it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 20.01it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.47it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.11it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.4422364234924316, 'eval_accuracy': 0.5531794428825378, 'eval_runtime': 2.8761, 'eval_samples_per_second': 1307.313, 'eval_steps_per_second': 20.514, 'epoch': 5.12}\n",
            " 72% 36000/50000 [55:17<21:01, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 19.21it/s]\u001b[A\n",
            "{'loss': 2.4897, 'grad_norm': 1.266683578491211, 'learning_rate': 0.00015516666666666668, 'epoch': 5.12}\n",
            "{'loss': 2.4829, 'grad_norm': 1.384833574295044, 'learning_rate': 0.00015461111111111112, 'epoch': 5.13}\n",
            "{'loss': 2.4848, 'grad_norm': 1.3830140829086304, 'learning_rate': 0.00015405555555555555, 'epoch': 5.14}\n",
            "{'loss': 2.4678, 'grad_norm': 1.3837347030639648, 'learning_rate': 0.0001535, 'epoch': 5.14}\n",
            "{'loss': 2.4974, 'grad_norm': 1.2763420343399048, 'learning_rate': 0.00015294444444444445, 'epoch': 5.15}\n",
            "{'loss': 2.4676, 'grad_norm': 1.3160854578018188, 'learning_rate': 0.0001523888888888889, 'epoch': 5.16}\n",
            "{'loss': 2.5043, 'grad_norm': 1.3519079685211182, 'learning_rate': 0.00015183333333333333, 'epoch': 5.17}\n",
            "{'loss': 2.4447, 'grad_norm': 1.416393518447876, 'learning_rate': 0.0001512777777777778, 'epoch': 5.17}\n",
            "{'loss': 2.483, 'grad_norm': 1.3253496885299683, 'learning_rate': 0.00015072222222222223, 'epoch': 5.18}\n",
            "{'loss': 2.4818, 'grad_norm': 1.3402577638626099, 'learning_rate': 0.00015016666666666667, 'epoch': 5.19}\n",
            "{'loss': 2.4773, 'grad_norm': 1.449981927871704, 'learning_rate': 0.0001496111111111111, 'epoch': 5.19}\n",
            "{'loss': 2.4442, 'grad_norm': 1.5315572023391724, 'learning_rate': 0.00014905555555555557, 'epoch': 5.2}\n",
            "{'loss': 2.4784, 'grad_norm': 1.3764454126358032, 'learning_rate': 0.0001485, 'epoch': 5.21}\n",
            "{'loss': 2.4516, 'grad_norm': 1.3822189569473267, 'learning_rate': 0.00014794444444444444, 'epoch': 5.22}\n",
            "{'loss': 2.4665, 'grad_norm': 1.4625694751739502, 'learning_rate': 0.0001474, 'epoch': 5.22}\n",
            "{'loss': 2.4577, 'grad_norm': 1.5000971555709839, 'learning_rate': 0.00014684444444444444, 'epoch': 5.23}\n",
            "{'loss': 2.483, 'grad_norm': 1.4605324268341064, 'learning_rate': 0.00014628888888888888, 'epoch': 5.24}\n",
            "{'loss': 2.4735, 'grad_norm': 1.4366481304168701, 'learning_rate': 0.00014573333333333332, 'epoch': 5.24}\n",
            "{'loss': 2.4615, 'grad_norm': 1.3142741918563843, 'learning_rate': 0.00014517777777777778, 'epoch': 5.25}\n",
            "{'loss': 2.4802, 'grad_norm': 1.4081337451934814, 'learning_rate': 0.00014462222222222224, 'epoch': 5.26}\n",
            "{'loss': 2.4893, 'grad_norm': 1.402130126953125, 'learning_rate': 0.00014406666666666668, 'epoch': 5.27}\n",
            "{'loss': 2.465, 'grad_norm': 1.5217244625091553, 'learning_rate': 0.00014351111111111112, 'epoch': 5.27}\n",
            "{'loss': 2.4678, 'grad_norm': 1.3923237323760986, 'learning_rate': 0.00014295555555555555, 'epoch': 5.28}\n",
            "{'loss': 2.4637, 'grad_norm': 1.328109622001648, 'learning_rate': 0.0001424, 'epoch': 5.29}\n",
            "{'loss': 2.4913, 'grad_norm': 1.4399151802062988, 'learning_rate': 0.00014184444444444446, 'epoch': 5.29}\n",
            "{'loss': 2.4733, 'grad_norm': 1.3377087116241455, 'learning_rate': 0.0001412888888888889, 'epoch': 5.3}\n",
            "{'loss': 2.4654, 'grad_norm': 1.4579753875732422, 'learning_rate': 0.00014073333333333333, 'epoch': 5.31}\n",
            "{'loss': 2.475, 'grad_norm': 1.371961236000061, 'learning_rate': 0.0001401777777777778, 'epoch': 5.31}\n",
            "{'loss': 2.4649, 'grad_norm': 1.534473180770874, 'learning_rate': 0.00013962222222222223, 'epoch': 5.32}\n",
            "{'loss': 2.4771, 'grad_norm': 1.3951972723007202, 'learning_rate': 0.00013906666666666667, 'epoch': 5.33}\n",
            "{'loss': 2.4908, 'grad_norm': 1.4252163171768188, 'learning_rate': 0.0001385111111111111, 'epoch': 5.34}\n",
            "{'loss': 2.4553, 'grad_norm': 1.2688685655593872, 'learning_rate': 0.00013795555555555557, 'epoch': 5.34}\n",
            "{'loss': 2.475, 'grad_norm': 1.3060860633850098, 'learning_rate': 0.0001374, 'epoch': 5.35}\n",
            "{'loss': 2.4721, 'grad_norm': 1.2874565124511719, 'learning_rate': 0.00013684444444444444, 'epoch': 5.36}\n",
            "{'loss': 2.4605, 'grad_norm': 1.4263132810592651, 'learning_rate': 0.00013628888888888888, 'epoch': 5.36}\n",
            "{'loss': 2.4629, 'grad_norm': 1.4804192781448364, 'learning_rate': 0.00013573333333333334, 'epoch': 5.37}\n",
            "{'loss': 2.4532, 'grad_norm': 1.3588944673538208, 'learning_rate': 0.00013517777777777778, 'epoch': 5.38}\n",
            "{'loss': 2.4491, 'grad_norm': 1.318124532699585, 'learning_rate': 0.00013462222222222222, 'epoch': 5.39}\n",
            "{'loss': 2.4528, 'grad_norm': 1.3912376165390015, 'learning_rate': 0.00013406666666666668, 'epoch': 5.39}\n",
            "{'loss': 2.4721, 'grad_norm': 1.3363885879516602, 'learning_rate': 0.00013351111111111112, 'epoch': 5.4}\n",
            " 76% 38000/50000 [58:18<18:00, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 43.01it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 42.80it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 41.95it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.69it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 29.09it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.75it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 22.87it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.51it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.51it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 22.05it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.73it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 20.39it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.51it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 19.19it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 2.453230381011963, 'eval_accuracy': 0.5509049296379089, 'eval_runtime': 2.8608, 'eval_samples_per_second': 1314.316, 'eval_steps_per_second': 20.624, 'epoch': 5.4}\n",
            " 76% 38000/50000 [58:21<18:00, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 18.93it/s]\u001b[A\n",
            "{'loss': 2.4606, 'grad_norm': 1.4385467767715454, 'learning_rate': 0.00013295555555555556, 'epoch': 5.41}\n",
            "{'loss': 2.4556, 'grad_norm': 1.388687252998352, 'learning_rate': 0.0001324, 'epoch': 5.41}\n",
            "{'loss': 2.442, 'grad_norm': 1.439961552619934, 'learning_rate': 0.00013184444444444443, 'epoch': 5.42}\n",
            "{'loss': 2.4574, 'grad_norm': 1.3904316425323486, 'learning_rate': 0.0001312888888888889, 'epoch': 5.43}\n",
            "{'loss': 2.4567, 'grad_norm': 1.4407309293746948, 'learning_rate': 0.00013073333333333333, 'epoch': 5.44}\n",
            "{'loss': 2.4409, 'grad_norm': 1.3960508108139038, 'learning_rate': 0.0001301777777777778, 'epoch': 5.44}\n",
            "{'loss': 2.4703, 'grad_norm': 1.386648178100586, 'learning_rate': 0.00012962222222222223, 'epoch': 5.45}\n",
            "{'loss': 2.463, 'grad_norm': 1.2631243467330933, 'learning_rate': 0.00012906666666666667, 'epoch': 5.46}\n",
            "{'loss': 2.4623, 'grad_norm': 1.4184023141860962, 'learning_rate': 0.0001285111111111111, 'epoch': 5.46}\n",
            "{'loss': 2.4584, 'grad_norm': 1.380509614944458, 'learning_rate': 0.00012795555555555554, 'epoch': 5.47}\n",
            "{'loss': 2.4488, 'grad_norm': 1.3894129991531372, 'learning_rate': 0.0001274, 'epoch': 5.48}\n",
            "{'loss': 2.4523, 'grad_norm': 1.4675601720809937, 'learning_rate': 0.00012684444444444444, 'epoch': 5.49}\n",
            "{'loss': 2.458, 'grad_norm': 1.406482219696045, 'learning_rate': 0.0001262888888888889, 'epoch': 5.49}\n",
            "{'loss': 2.4392, 'grad_norm': 1.4187109470367432, 'learning_rate': 0.00012573333333333334, 'epoch': 5.5}\n",
            "{'loss': 2.4682, 'grad_norm': 1.362708330154419, 'learning_rate': 0.00012518888888888888, 'epoch': 5.51}\n",
            "{'loss': 2.4279, 'grad_norm': 1.3672021627426147, 'learning_rate': 0.00012463333333333335, 'epoch': 5.51}\n",
            "{'loss': 2.4548, 'grad_norm': 1.34030020236969, 'learning_rate': 0.00012407777777777778, 'epoch': 5.52}\n",
            "{'loss': 2.4445, 'grad_norm': 1.3357880115509033, 'learning_rate': 0.00012352222222222222, 'epoch': 5.53}\n",
            "{'loss': 2.4465, 'grad_norm': 1.3280383348464966, 'learning_rate': 0.00012296666666666668, 'epoch': 5.54}\n",
            "{'loss': 2.4304, 'grad_norm': 1.4939531087875366, 'learning_rate': 0.00012241111111111112, 'epoch': 5.54}\n",
            "{'loss': 2.444, 'grad_norm': 1.4064017534255981, 'learning_rate': 0.00012185555555555556, 'epoch': 5.55}\n",
            "{'loss': 2.4386, 'grad_norm': 1.2962861061096191, 'learning_rate': 0.00012130000000000001, 'epoch': 5.56}\n",
            "{'loss': 2.4584, 'grad_norm': 1.3781431913375854, 'learning_rate': 0.00012074444444444444, 'epoch': 5.56}\n",
            "{'loss': 2.4745, 'grad_norm': 1.4188493490219116, 'learning_rate': 0.0001201888888888889, 'epoch': 5.57}\n",
            "{'loss': 2.4501, 'grad_norm': 1.6039015054702759, 'learning_rate': 0.00011963333333333333, 'epoch': 5.58}\n",
            "{'loss': 2.4376, 'grad_norm': 1.4177863597869873, 'learning_rate': 0.00011907777777777778, 'epoch': 5.58}\n",
            "{'loss': 2.4224, 'grad_norm': 1.2840189933776855, 'learning_rate': 0.00011852222222222222, 'epoch': 5.59}\n",
            "{'loss': 2.4491, 'grad_norm': 1.4394868612289429, 'learning_rate': 0.00011796666666666667, 'epoch': 5.6}\n",
            "{'loss': 2.43, 'grad_norm': 1.4475663900375366, 'learning_rate': 0.00011741111111111111, 'epoch': 5.61}\n",
            "{'loss': 2.439, 'grad_norm': 1.3510189056396484, 'learning_rate': 0.00011685555555555556, 'epoch': 5.61}\n",
            "{'loss': 2.4522, 'grad_norm': 1.4517143964767456, 'learning_rate': 0.00011630000000000001, 'epoch': 5.62}\n",
            "{'loss': 2.4471, 'grad_norm': 1.4200923442840576, 'learning_rate': 0.00011574444444444444, 'epoch': 5.63}\n",
            "{'loss': 2.436, 'grad_norm': 1.4068219661712646, 'learning_rate': 0.00011518888888888888, 'epoch': 5.63}\n",
            "{'loss': 2.4394, 'grad_norm': 1.4703913927078247, 'learning_rate': 0.00011463333333333335, 'epoch': 5.64}\n",
            "{'loss': 2.451, 'grad_norm': 1.3528081178665161, 'learning_rate': 0.00011407777777777778, 'epoch': 5.65}\n",
            "{'loss': 2.4547, 'grad_norm': 1.4417810440063477, 'learning_rate': 0.00011352222222222222, 'epoch': 5.66}\n",
            "{'loss': 2.4464, 'grad_norm': 1.3772097826004028, 'learning_rate': 0.00011296666666666667, 'epoch': 5.66}\n",
            "{'loss': 2.4244, 'grad_norm': 1.4133373498916626, 'learning_rate': 0.00011241111111111112, 'epoch': 5.67}\n",
            "{'loss': 2.4424, 'grad_norm': 1.389215111732483, 'learning_rate': 0.00011185555555555556, 'epoch': 5.68}\n",
            "{'loss': 2.4277, 'grad_norm': 1.4879623651504517, 'learning_rate': 0.0001113, 'epoch': 5.68}\n",
            " 80% 40000/50000 [1:01:22<15:07, 11.02it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.93it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.95it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 43.26it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.98it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 28.76it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.59it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 22.76it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.35it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.48it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.82it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 21.46it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.34it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 20.06it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 19.51it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 19.17it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.4423093795776367, 'eval_accuracy': 0.5560587048530579, 'eval_runtime': 2.8649, 'eval_samples_per_second': 1312.438, 'eval_steps_per_second': 20.594, 'epoch': 5.68}\n",
            " 80% 40000/50000 [1:01:24<15:07, 11.02it/s]\n",
            "100% 59/59 [00:02<00:00, 18.94it/s]\u001b[A\n",
            "{'loss': 2.4463, 'grad_norm': 1.466772198677063, 'learning_rate': 0.00011074444444444446, 'epoch': 5.69}\n",
            "{'loss': 2.4508, 'grad_norm': 1.4807891845703125, 'learning_rate': 0.0001101888888888889, 'epoch': 5.7}\n",
            "{'loss': 2.4262, 'grad_norm': 1.3899619579315186, 'learning_rate': 0.00010963333333333333, 'epoch': 5.71}\n",
            "{'loss': 2.4266, 'grad_norm': 1.5103718042373657, 'learning_rate': 0.00010907777777777777, 'epoch': 5.71}\n",
            "{'loss': 2.4399, 'grad_norm': 1.3556782007217407, 'learning_rate': 0.00010852222222222223, 'epoch': 5.72}\n",
            "{'loss': 2.4168, 'grad_norm': 1.3653018474578857, 'learning_rate': 0.00010796666666666667, 'epoch': 5.73}\n",
            "{'loss': 2.4576, 'grad_norm': 1.3659559488296509, 'learning_rate': 0.00010741111111111111, 'epoch': 5.73}\n",
            "{'loss': 2.4394, 'grad_norm': 1.3831312656402588, 'learning_rate': 0.00010685555555555556, 'epoch': 5.74}\n",
            "{'loss': 2.4455, 'grad_norm': 1.3189468383789062, 'learning_rate': 0.00010630000000000001, 'epoch': 5.75}\n",
            "{'loss': 2.4457, 'grad_norm': 1.3535090684890747, 'learning_rate': 0.00010574444444444445, 'epoch': 5.76}\n",
            "{'loss': 2.4191, 'grad_norm': 1.411381721496582, 'learning_rate': 0.00010518888888888888, 'epoch': 5.76}\n",
            "{'loss': 2.4375, 'grad_norm': 1.4552092552185059, 'learning_rate': 0.00010463333333333333, 'epoch': 5.77}\n",
            "{'loss': 2.4283, 'grad_norm': 1.3475172519683838, 'learning_rate': 0.00010407777777777778, 'epoch': 5.78}\n",
            "{'loss': 2.4592, 'grad_norm': 1.3985308408737183, 'learning_rate': 0.00010352222222222222, 'epoch': 5.78}\n",
            "{'loss': 2.4296, 'grad_norm': inf, 'learning_rate': 0.00010296666666666667, 'epoch': 5.79}\n",
            "{'loss': 2.4295, 'grad_norm': 1.52768874168396, 'learning_rate': 0.00010242222222222222, 'epoch': 5.8}\n",
            "{'loss': 2.4209, 'grad_norm': 1.3441251516342163, 'learning_rate': 0.00010186666666666666, 'epoch': 5.81}\n",
            "{'loss': 2.4415, 'grad_norm': 1.3889893293380737, 'learning_rate': 0.00010131111111111112, 'epoch': 5.81}\n",
            "{'loss': 2.4122, 'grad_norm': 1.3421958684921265, 'learning_rate': 0.00010075555555555556, 'epoch': 5.82}\n",
            "{'loss': 2.4433, 'grad_norm': 1.4494398832321167, 'learning_rate': 0.0001002, 'epoch': 5.83}\n",
            "{'loss': 2.3957, 'grad_norm': 1.3757388591766357, 'learning_rate': 9.964444444444445e-05, 'epoch': 5.83}\n",
            "{'loss': 2.4232, 'grad_norm': 1.4007952213287354, 'learning_rate': 9.90888888888889e-05, 'epoch': 5.84}\n",
            "{'loss': 2.4113, 'grad_norm': 1.3470393419265747, 'learning_rate': 9.853333333333333e-05, 'epoch': 5.85}\n",
            "{'loss': 2.4303, 'grad_norm': 1.3714083433151245, 'learning_rate': 9.797777777777777e-05, 'epoch': 5.85}\n",
            "{'loss': 2.4376, 'grad_norm': 1.3842213153839111, 'learning_rate': 9.742222222222222e-05, 'epoch': 5.86}\n",
            "{'loss': 2.4414, 'grad_norm': 1.410214900970459, 'learning_rate': 9.686666666666667e-05, 'epoch': 5.87}\n",
            "{'loss': 2.4374, 'grad_norm': 1.4616345167160034, 'learning_rate': 9.631111111111111e-05, 'epoch': 5.88}\n",
            "{'loss': 2.4183, 'grad_norm': 1.4112011194229126, 'learning_rate': 9.575555555555556e-05, 'epoch': 5.88}\n",
            "{'loss': 2.4463, 'grad_norm': 1.366767168045044, 'learning_rate': 9.520000000000001e-05, 'epoch': 5.89}\n",
            "{'loss': 2.4214, 'grad_norm': 1.4703049659729004, 'learning_rate': 9.464444444444445e-05, 'epoch': 5.9}\n",
            "{'loss': 2.4363, 'grad_norm': 1.4820811748504639, 'learning_rate': 9.408888888888888e-05, 'epoch': 5.9}\n",
            "{'loss': 2.423, 'grad_norm': 1.411631464958191, 'learning_rate': 9.353333333333333e-05, 'epoch': 5.91}\n",
            "{'loss': 2.4197, 'grad_norm': 1.4232956171035767, 'learning_rate': 9.297777777777779e-05, 'epoch': 5.92}\n",
            "{'loss': 2.4122, 'grad_norm': 1.361301064491272, 'learning_rate': 9.242222222222222e-05, 'epoch': 5.93}\n",
            "{'loss': 2.4164, 'grad_norm': 1.4716687202453613, 'learning_rate': 9.186666666666667e-05, 'epoch': 5.93}\n",
            "{'loss': 2.4099, 'grad_norm': 1.38069748878479, 'learning_rate': 9.131111111111111e-05, 'epoch': 5.94}\n",
            "{'loss': 2.4186, 'grad_norm': 1.4138333797454834, 'learning_rate': 9.075555555555556e-05, 'epoch': 5.95}\n",
            "{'loss': 2.4204, 'grad_norm': 1.379775047302246, 'learning_rate': 9.020000000000001e-05, 'epoch': 5.95}\n",
            "{'loss': 2.421, 'grad_norm': 1.4364006519317627, 'learning_rate': 8.964444444444445e-05, 'epoch': 5.96}\n",
            "{'loss': 2.4143, 'grad_norm': 1.458503246307373, 'learning_rate': 8.908888888888888e-05, 'epoch': 5.97}\n",
            " 84% 42000/50000 [1:04:25<12:00, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 45.05it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 44.66it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.18it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.12it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.05it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.21it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.81it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.07it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 19.92it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 18.58it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.34it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.02it/s]\u001b[A\n",
            " 83% 49/59 [00:02<00:00, 18.77it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.71it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.66it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 19.68it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.429431438446045, 'eval_accuracy': 0.55959552526474, 'eval_runtime': 2.9416, 'eval_samples_per_second': 1278.221, 'eval_steps_per_second': 20.057, 'epoch': 5.97}\n",
            " 84% 42000/50000 [1:04:28<12:00, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 18.03it/s]\u001b[A\n",
            "{'loss': 2.4082, 'grad_norm': 1.5280762910842896, 'learning_rate': 8.853333333333333e-05, 'epoch': 5.98}\n",
            "{'loss': 2.3986, 'grad_norm': 1.4531466960906982, 'learning_rate': 8.797777777777779e-05, 'epoch': 5.98}\n",
            "{'loss': 2.4081, 'grad_norm': 1.5270668268203735, 'learning_rate': 8.742222222222222e-05, 'epoch': 5.99}\n",
            "{'loss': 2.4008, 'grad_norm': 1.478691816329956, 'learning_rate': 8.686666666666666e-05, 'epoch': 6.0}\n",
            "{'loss': 2.3947, 'grad_norm': 1.4526691436767578, 'learning_rate': 8.631111111111112e-05, 'epoch': 6.0}\n",
            "{'loss': 2.4034, 'grad_norm': 1.4210879802703857, 'learning_rate': 8.575555555555556e-05, 'epoch': 6.01}\n",
            "{'loss': 2.3958, 'grad_norm': 1.3216043710708618, 'learning_rate': 8.52e-05, 'epoch': 6.02}\n",
            "{'loss': 2.4208, 'grad_norm': 1.3741506338119507, 'learning_rate': 8.464444444444443e-05, 'epoch': 6.03}\n",
            "{'loss': 2.4031, 'grad_norm': 1.4078813791275024, 'learning_rate': 8.40888888888889e-05, 'epoch': 6.03}\n",
            "{'loss': 2.3913, 'grad_norm': 1.3755744695663452, 'learning_rate': 8.353333333333334e-05, 'epoch': 6.04}\n",
            "{'loss': 2.4035, 'grad_norm': 1.4538395404815674, 'learning_rate': 8.297777777777777e-05, 'epoch': 6.05}\n",
            "{'loss': 2.4195, 'grad_norm': 1.359370470046997, 'learning_rate': 8.242222222222222e-05, 'epoch': 6.05}\n",
            "{'loss': 2.4055, 'grad_norm': 1.3453381061553955, 'learning_rate': 8.186666666666667e-05, 'epoch': 6.06}\n",
            "{'loss': 2.41, 'grad_norm': 1.3704077005386353, 'learning_rate': 8.131111111111111e-05, 'epoch': 6.07}\n",
            "{'loss': 2.4001, 'grad_norm': 1.4593384265899658, 'learning_rate': 8.075555555555556e-05, 'epoch': 6.08}\n",
            "{'loss': 2.3973, 'grad_norm': 1.4380100965499878, 'learning_rate': 8.021111111111111e-05, 'epoch': 6.08}\n",
            "{'loss': 2.411, 'grad_norm': 1.5241674184799194, 'learning_rate': 7.965555555555555e-05, 'epoch': 6.09}\n",
            "{'loss': 2.392, 'grad_norm': 1.403864860534668, 'learning_rate': 7.910000000000001e-05, 'epoch': 6.1}\n",
            "{'loss': 2.385, 'grad_norm': 1.4746441841125488, 'learning_rate': 7.854444444444445e-05, 'epoch': 6.1}\n",
            "{'loss': 2.4018, 'grad_norm': 1.3884705305099487, 'learning_rate': 7.798888888888889e-05, 'epoch': 6.11}\n",
            "{'loss': 2.3904, 'grad_norm': 1.4237414598464966, 'learning_rate': 7.743333333333334e-05, 'epoch': 6.12}\n",
            "{'loss': 2.3931, 'grad_norm': 1.3911137580871582, 'learning_rate': 7.687777777777779e-05, 'epoch': 6.12}\n",
            "{'loss': 2.3856, 'grad_norm': 1.4306535720825195, 'learning_rate': 7.632222222222222e-05, 'epoch': 6.13}\n",
            "{'loss': 2.3942, 'grad_norm': 1.3952072858810425, 'learning_rate': 7.576666666666666e-05, 'epoch': 6.14}\n",
            "{'loss': 2.3771, 'grad_norm': 1.4383608102798462, 'learning_rate': 7.521111111111112e-05, 'epoch': 6.15}\n",
            "{'loss': 2.4085, 'grad_norm': 1.3761874437332153, 'learning_rate': 7.465555555555556e-05, 'epoch': 6.15}\n",
            "{'loss': 2.4036, 'grad_norm': 1.3636114597320557, 'learning_rate': 7.41e-05, 'epoch': 6.16}\n",
            "{'loss': 2.4068, 'grad_norm': 1.4424196481704712, 'learning_rate': 7.354444444444444e-05, 'epoch': 6.17}\n",
            "{'loss': 2.404, 'grad_norm': 1.4282000064849854, 'learning_rate': 7.29888888888889e-05, 'epoch': 6.17}\n",
            "{'loss': 2.3738, 'grad_norm': 1.447745442390442, 'learning_rate': 7.243333333333334e-05, 'epoch': 6.18}\n",
            "{'loss': 2.379, 'grad_norm': 1.3567023277282715, 'learning_rate': 7.187777777777777e-05, 'epoch': 6.19}\n",
            "{'loss': 2.3788, 'grad_norm': 1.5197815895080566, 'learning_rate': 7.132222222222222e-05, 'epoch': 6.2}\n",
            "{'loss': 2.3899, 'grad_norm': 1.3931211233139038, 'learning_rate': 7.076666666666667e-05, 'epoch': 6.2}\n",
            "{'loss': 2.3828, 'grad_norm': 1.3606287240982056, 'learning_rate': 7.021111111111111e-05, 'epoch': 6.21}\n",
            "{'loss': 2.3747, 'grad_norm': 1.474198341369629, 'learning_rate': 6.965555555555555e-05, 'epoch': 6.22}\n",
            "{'loss': 2.3958, 'grad_norm': 1.4924707412719727, 'learning_rate': 6.91e-05, 'epoch': 6.22}\n",
            "{'loss': 2.4068, 'grad_norm': 1.476428747177124, 'learning_rate': 6.854444444444445e-05, 'epoch': 6.23}\n",
            "{'loss': 2.4024, 'grad_norm': 1.36684250831604, 'learning_rate': 6.798888888888889e-05, 'epoch': 6.24}\n",
            "{'loss': 2.3782, 'grad_norm': 1.5700349807739258, 'learning_rate': 6.743333333333334e-05, 'epoch': 6.25}\n",
            "{'loss': 2.3993, 'grad_norm': 1.4550331830978394, 'learning_rate': 6.687777777777777e-05, 'epoch': 6.25}\n",
            " 88% 44000/50000 [1:07:30<08:59, 11.13it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 46.86it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 45.39it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:00, 44.74it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 44.45it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 30.09it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 25.26it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 23.20it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 21.68it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.66it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.04it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.74it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 20.31it/s]\u001b[A\n",
            " 85% 50/59 [00:02<00:00, 19.64it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.26it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.27it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.4179000854492188, 'eval_accuracy': 0.5623570680618286, 'eval_runtime': 2.848, 'eval_samples_per_second': 1320.236, 'eval_steps_per_second': 20.716, 'epoch': 6.25}\n",
            " 88% 44000/50000 [1:07:33<08:59, 11.13it/s]\n",
            "100% 59/59 [00:02<00:00, 18.74it/s]\u001b[A\n",
            "{'loss': 2.3592, 'grad_norm': 1.4233587980270386, 'learning_rate': 6.632222222222222e-05, 'epoch': 6.26}\n",
            "{'loss': 2.4105, 'grad_norm': 1.4531817436218262, 'learning_rate': 6.576666666666668e-05, 'epoch': 6.27}\n",
            "{'loss': 2.3834, 'grad_norm': 1.515326976776123, 'learning_rate': 6.521111111111111e-05, 'epoch': 6.27}\n",
            "{'loss': 2.3805, 'grad_norm': 1.4109193086624146, 'learning_rate': 6.465555555555555e-05, 'epoch': 6.28}\n",
            "{'loss': 2.4044, 'grad_norm': 1.508571982383728, 'learning_rate': 6.41e-05, 'epoch': 6.29}\n",
            "{'loss': 2.3945, 'grad_norm': 1.5521471500396729, 'learning_rate': 6.354444444444445e-05, 'epoch': 6.3}\n",
            "{'loss': 2.3764, 'grad_norm': 1.4900389909744263, 'learning_rate': 6.298888888888889e-05, 'epoch': 6.3}\n",
            "{'loss': 2.3996, 'grad_norm': 1.5257790088653564, 'learning_rate': 6.243333333333334e-05, 'epoch': 6.31}\n",
            "{'loss': 2.3845, 'grad_norm': 1.4425104856491089, 'learning_rate': 6.187777777777777e-05, 'epoch': 6.32}\n",
            "{'loss': 2.3823, 'grad_norm': 1.4904192686080933, 'learning_rate': 6.132222222222223e-05, 'epoch': 6.32}\n",
            "{'loss': 2.3718, 'grad_norm': 1.4389290809631348, 'learning_rate': 6.076666666666666e-05, 'epoch': 6.33}\n",
            "{'loss': 2.3725, 'grad_norm': 1.353135585784912, 'learning_rate': 6.021111111111111e-05, 'epoch': 6.34}\n",
            "{'loss': 2.3736, 'grad_norm': 1.4234167337417603, 'learning_rate': 5.965555555555556e-05, 'epoch': 6.35}\n",
            "{'loss': 2.3759, 'grad_norm': 1.4493889808654785, 'learning_rate': 5.91e-05, 'epoch': 6.35}\n",
            "{'loss': 2.3918, 'grad_norm': 1.3667247295379639, 'learning_rate': 5.854444444444445e-05, 'epoch': 6.36}\n",
            "{'loss': 2.4105, 'grad_norm': 1.4009673595428467, 'learning_rate': 5.800000000000001e-05, 'epoch': 6.37}\n",
            "{'loss': 2.4008, 'grad_norm': 1.4112690687179565, 'learning_rate': 5.7444444444444444e-05, 'epoch': 6.37}\n",
            "{'loss': 2.3905, 'grad_norm': 1.3765161037445068, 'learning_rate': 5.6888888888888895e-05, 'epoch': 6.38}\n",
            "{'loss': 2.3769, 'grad_norm': 1.3404569625854492, 'learning_rate': 5.633333333333333e-05, 'epoch': 6.39}\n",
            "{'loss': 2.3927, 'grad_norm': 1.5139946937561035, 'learning_rate': 5.577777777777778e-05, 'epoch': 6.39}\n",
            "{'loss': 2.3921, 'grad_norm': 1.4771400690078735, 'learning_rate': 5.522222222222222e-05, 'epoch': 6.4}\n",
            "{'loss': 2.3787, 'grad_norm': 1.360882043838501, 'learning_rate': 5.466666666666667e-05, 'epoch': 6.41}\n",
            "{'loss': 2.4011, 'grad_norm': 1.4640988111495972, 'learning_rate': 5.411111111111111e-05, 'epoch': 6.42}\n",
            "{'loss': 2.3755, 'grad_norm': 1.469592809677124, 'learning_rate': 5.355555555555556e-05, 'epoch': 6.42}\n",
            "{'loss': 2.3735, 'grad_norm': 1.3934208154678345, 'learning_rate': 5.3e-05, 'epoch': 6.43}\n",
            "{'loss': 2.356, 'grad_norm': 1.5128930807113647, 'learning_rate': 5.2444444444444445e-05, 'epoch': 6.44}\n",
            "{'loss': 2.3673, 'grad_norm': 1.490496039390564, 'learning_rate': 5.188888888888889e-05, 'epoch': 6.44}\n",
            "{'loss': 2.3859, 'grad_norm': 1.373136281967163, 'learning_rate': 5.133333333333334e-05, 'epoch': 6.45}\n",
            "{'loss': 2.384, 'grad_norm': 1.6516081094741821, 'learning_rate': 5.0777777777777776e-05, 'epoch': 6.46}\n",
            "{'loss': 2.375, 'grad_norm': 1.5445526838302612, 'learning_rate': 5.0222222222222226e-05, 'epoch': 6.47}\n",
            "{'loss': 2.3487, 'grad_norm': 1.4801661968231201, 'learning_rate': 4.966666666666666e-05, 'epoch': 6.47}\n",
            "{'loss': 2.3974, 'grad_norm': 1.4183918237686157, 'learning_rate': 4.9111111111111114e-05, 'epoch': 6.48}\n",
            "{'loss': 2.373, 'grad_norm': 1.3616260290145874, 'learning_rate': 4.855555555555556e-05, 'epoch': 6.49}\n",
            "{'loss': 2.3898, 'grad_norm': 1.381722331047058, 'learning_rate': 4.8e-05, 'epoch': 6.49}\n",
            "{'loss': 2.3758, 'grad_norm': 1.5327140092849731, 'learning_rate': 4.7444444444444445e-05, 'epoch': 6.5}\n",
            "{'loss': 2.3625, 'grad_norm': 1.391097068786621, 'learning_rate': 4.688888888888889e-05, 'epoch': 6.51}\n",
            "{'loss': 2.3807, 'grad_norm': 1.3533554077148438, 'learning_rate': 4.633333333333333e-05, 'epoch': 6.52}\n",
            "{'loss': 2.3724, 'grad_norm': 1.4423617124557495, 'learning_rate': 4.5777777777777776e-05, 'epoch': 6.52}\n",
            "{'loss': 2.3824, 'grad_norm': 1.4371126890182495, 'learning_rate': 4.522222222222222e-05, 'epoch': 6.53}\n",
            "{'loss': 2.383, 'grad_norm': 1.4162564277648926, 'learning_rate': 4.466666666666667e-05, 'epoch': 6.54}\n",
            " 92% 46000/50000 [1:10:34<06:00, 11.11it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  7% 4/59 [00:00<00:01, 39.78it/s]\u001b[A\n",
            " 15% 9/59 [00:00<00:01, 42.60it/s]\u001b[A\n",
            " 24% 14/59 [00:00<00:01, 42.43it/s]\u001b[A\n",
            " 32% 19/59 [00:00<00:00, 42.53it/s]\u001b[A\n",
            " 41% 24/59 [00:00<00:01, 33.52it/s]\u001b[A\n",
            " 47% 28/59 [00:00<00:01, 28.10it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 24.23it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.43it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.20it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 19.30it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.06it/s]\u001b[A\n",
            " 78% 46/59 [00:01<00:00, 18.83it/s]\u001b[A\n",
            " 83% 49/59 [00:02<00:00, 19.73it/s]\u001b[A\n",
            " 88% 52/59 [00:02<00:00, 19.26it/s]\u001b[A\n",
            " 92% 54/59 [00:02<00:00, 19.09it/s]\u001b[A\n",
            " 95% 56/59 [00:02<00:00, 18.86it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.3925459384918213, 'eval_accuracy': 0.5684603452682495, 'eval_runtime': 2.9355, 'eval_samples_per_second': 1280.883, 'eval_steps_per_second': 20.099, 'epoch': 6.54}\n",
            " 92% 46000/50000 [1:10:37<06:00, 11.11it/s]\n",
            "100% 59/59 [00:02<00:00, 16.52it/s]\u001b[A\n",
            "{'loss': 2.3842, 'grad_norm': 1.5549366474151611, 'learning_rate': 4.411111111111111e-05, 'epoch': 6.54}\n",
            "{'loss': 2.3885, 'grad_norm': 1.373586893081665, 'learning_rate': 4.355555555555556e-05, 'epoch': 6.55}\n",
            "{'loss': 2.3745, 'grad_norm': 1.435160756111145, 'learning_rate': 4.2999999999999995e-05, 'epoch': 6.56}\n",
            "{'loss': 2.3733, 'grad_norm': 1.5209007263183594, 'learning_rate': 4.2444444444444445e-05, 'epoch': 6.57}\n",
            "{'loss': 2.3699, 'grad_norm': 1.3987706899642944, 'learning_rate': 4.1888888888888896e-05, 'epoch': 6.57}\n",
            "{'loss': 2.3863, 'grad_norm': 1.493683099746704, 'learning_rate': 4.133333333333333e-05, 'epoch': 6.58}\n",
            "{'loss': 2.3727, 'grad_norm': 1.391727089881897, 'learning_rate': 4.0777777777777783e-05, 'epoch': 6.59}\n",
            "{'loss': 2.3683, 'grad_norm': 1.373101830482483, 'learning_rate': 4.022222222222222e-05, 'epoch': 6.59}\n",
            "{'loss': 2.3805, 'grad_norm': 1.5206823348999023, 'learning_rate': 3.966666666666667e-05, 'epoch': 6.6}\n",
            "{'loss': 2.3835, 'grad_norm': 1.545150876045227, 'learning_rate': 3.911111111111111e-05, 'epoch': 6.61}\n",
            "{'loss': 2.3642, 'grad_norm': 1.4071186780929565, 'learning_rate': 3.855555555555556e-05, 'epoch': 6.62}\n",
            "{'loss': 2.3784, 'grad_norm': 1.386426568031311, 'learning_rate': 3.8e-05, 'epoch': 6.62}\n",
            "{'loss': 2.3709, 'grad_norm': 1.4494218826293945, 'learning_rate': 3.7444444444444446e-05, 'epoch': 6.63}\n",
            "{'loss': 2.3654, 'grad_norm': 1.3512589931488037, 'learning_rate': 3.688888888888889e-05, 'epoch': 6.64}\n",
            "{'loss': 2.3701, 'grad_norm': 1.5027416944503784, 'learning_rate': 3.633333333333333e-05, 'epoch': 6.64}\n",
            "{'loss': 2.3797, 'grad_norm': 1.43238365650177, 'learning_rate': 3.578888888888889e-05, 'epoch': 6.65}\n",
            "{'loss': 2.3585, 'grad_norm': 1.4054700136184692, 'learning_rate': 3.5233333333333334e-05, 'epoch': 6.66}\n",
            "{'loss': 2.3514, 'grad_norm': 1.406501054763794, 'learning_rate': 3.467777777777778e-05, 'epoch': 6.66}\n",
            "{'loss': 2.3604, 'grad_norm': 1.464880347251892, 'learning_rate': 3.412222222222222e-05, 'epoch': 6.67}\n",
            "{'loss': 2.3554, 'grad_norm': 1.500085711479187, 'learning_rate': 3.356666666666667e-05, 'epoch': 6.68}\n",
            "{'loss': 2.3606, 'grad_norm': 1.5191962718963623, 'learning_rate': 3.301111111111111e-05, 'epoch': 6.69}\n",
            "{'loss': 2.3728, 'grad_norm': 1.4286240339279175, 'learning_rate': 3.245555555555556e-05, 'epoch': 6.69}\n",
            "{'loss': 2.3568, 'grad_norm': 1.4180397987365723, 'learning_rate': 3.1899999999999996e-05, 'epoch': 6.7}\n",
            "{'loss': 2.3464, 'grad_norm': 1.5229641199111938, 'learning_rate': 3.134444444444445e-05, 'epoch': 6.71}\n",
            "{'loss': 2.3427, 'grad_norm': 1.4716063737869263, 'learning_rate': 3.078888888888889e-05, 'epoch': 6.71}\n",
            "{'loss': 2.3486, 'grad_norm': 1.4065712690353394, 'learning_rate': 3.0233333333333334e-05, 'epoch': 6.72}\n",
            "{'loss': 2.3597, 'grad_norm': 1.4930784702301025, 'learning_rate': 2.9677777777777778e-05, 'epoch': 6.73}\n",
            "{'loss': 2.3822, 'grad_norm': 1.5389364957809448, 'learning_rate': 2.9122222222222225e-05, 'epoch': 6.74}\n",
            "{'loss': 2.3599, 'grad_norm': 1.4005635976791382, 'learning_rate': 2.856666666666667e-05, 'epoch': 6.74}\n",
            "{'loss': 2.3464, 'grad_norm': 1.3658976554870605, 'learning_rate': 2.8011111111111112e-05, 'epoch': 6.75}\n",
            "{'loss': 2.3762, 'grad_norm': 1.4774593114852905, 'learning_rate': 2.7455555555555556e-05, 'epoch': 6.76}\n",
            "{'loss': 2.3407, 'grad_norm': 1.4621025323867798, 'learning_rate': 2.69e-05, 'epoch': 6.76}\n",
            "{'loss': 2.3632, 'grad_norm': 1.3460005521774292, 'learning_rate': 2.6344444444444444e-05, 'epoch': 6.77}\n",
            "{'loss': 2.3764, 'grad_norm': 1.5138676166534424, 'learning_rate': 2.578888888888889e-05, 'epoch': 6.78}\n",
            "{'loss': 2.3393, 'grad_norm': 1.5107256174087524, 'learning_rate': 2.5233333333333335e-05, 'epoch': 6.79}\n",
            "{'loss': 2.355, 'grad_norm': 1.4131102561950684, 'learning_rate': 2.4677777777777778e-05, 'epoch': 6.79}\n",
            "{'loss': 2.3563, 'grad_norm': 1.4262654781341553, 'learning_rate': 2.4122222222222222e-05, 'epoch': 6.8}\n",
            "{'loss': 2.3671, 'grad_norm': 1.481450080871582, 'learning_rate': 2.3566666666666666e-05, 'epoch': 6.81}\n",
            "{'loss': 2.3812, 'grad_norm': 1.4581671953201294, 'learning_rate': 2.301111111111111e-05, 'epoch': 6.81}\n",
            "{'loss': 2.3777, 'grad_norm': 1.4193118810653687, 'learning_rate': 2.2455555555555557e-05, 'epoch': 6.82}\n",
            " 96% 48000/50000 [1:13:38<03:00, 11.10it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.88it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 41.81it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 42.17it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 41.68it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 29.18it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 24.87it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 24.30it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 23.43it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:00, 21.80it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.70it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.92it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.42it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 19.18it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.94it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.74it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.68it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.46it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.348822832107544, 'eval_accuracy': 0.5688449144363403, 'eval_runtime': 2.8494, 'eval_samples_per_second': 1319.591, 'eval_steps_per_second': 20.706, 'epoch': 6.82}\n",
            " 96% 48000/50000 [1:13:41<03:00, 11.10it/s]\n",
            "100% 59/59 [00:02<00:00, 17.73it/s]\u001b[A\n",
            "{'loss': 2.3837, 'grad_norm': 1.4781115055084229, 'learning_rate': 2.19e-05, 'epoch': 6.83}\n",
            "{'loss': 2.3403, 'grad_norm': 1.448176383972168, 'learning_rate': 2.1344444444444444e-05, 'epoch': 6.84}\n",
            "{'loss': 2.3831, 'grad_norm': 1.3386389017105103, 'learning_rate': 2.0788888888888888e-05, 'epoch': 6.84}\n",
            "{'loss': 2.3751, 'grad_norm': 1.3743464946746826, 'learning_rate': 2.023333333333333e-05, 'epoch': 6.85}\n",
            "{'loss': 2.3671, 'grad_norm': 1.3278788328170776, 'learning_rate': 1.967777777777778e-05, 'epoch': 6.86}\n",
            "{'loss': 2.3671, 'grad_norm': 1.5685192346572876, 'learning_rate': 1.9122222222222222e-05, 'epoch': 6.86}\n",
            "{'loss': 2.354, 'grad_norm': 1.4491006135940552, 'learning_rate': 1.8566666666666666e-05, 'epoch': 6.87}\n",
            "{'loss': 2.3569, 'grad_norm': 1.4591739177703857, 'learning_rate': 1.801111111111111e-05, 'epoch': 6.88}\n",
            "{'loss': 2.3446, 'grad_norm': 1.3174197673797607, 'learning_rate': 1.7455555555555554e-05, 'epoch': 6.89}\n",
            "{'loss': 2.3542, 'grad_norm': 1.3992795944213867, 'learning_rate': 1.6899999999999997e-05, 'epoch': 6.89}\n",
            "{'loss': 2.3457, 'grad_norm': 1.413737416267395, 'learning_rate': 1.6344444444444448e-05, 'epoch': 6.9}\n",
            "{'loss': 2.3765, 'grad_norm': 1.391079306602478, 'learning_rate': 1.578888888888889e-05, 'epoch': 6.91}\n",
            "{'loss': 2.3499, 'grad_norm': 1.4873348474502563, 'learning_rate': 1.5233333333333334e-05, 'epoch': 6.91}\n",
            "{'loss': 2.3117, 'grad_norm': 1.3730841875076294, 'learning_rate': 1.4677777777777777e-05, 'epoch': 6.92}\n",
            "{'loss': 2.3603, 'grad_norm': 1.479299545288086, 'learning_rate': 1.4122222222222223e-05, 'epoch': 6.93}\n",
            "{'loss': 2.3821, 'grad_norm': 1.3679547309875488, 'learning_rate': 1.3577777777777778e-05, 'epoch': 6.93}\n",
            "{'loss': 2.3412, 'grad_norm': 1.3720792531967163, 'learning_rate': 1.3022222222222222e-05, 'epoch': 6.94}\n",
            "{'loss': 2.3263, 'grad_norm': 1.4437075853347778, 'learning_rate': 1.2466666666666665e-05, 'epoch': 6.95}\n",
            "{'loss': 2.3657, 'grad_norm': 1.3675624132156372, 'learning_rate': 1.1911111111111112e-05, 'epoch': 6.96}\n",
            "{'loss': 2.3547, 'grad_norm': 1.4609487056732178, 'learning_rate': 1.1355555555555556e-05, 'epoch': 6.96}\n",
            "{'loss': 2.343, 'grad_norm': 1.4445639848709106, 'learning_rate': 1.0800000000000002e-05, 'epoch': 6.97}\n",
            "{'loss': 2.366, 'grad_norm': 1.4239404201507568, 'learning_rate': 1.0244444444444445e-05, 'epoch': 6.98}\n",
            "{'loss': 2.3735, 'grad_norm': 1.4040802717208862, 'learning_rate': 9.688888888888889e-06, 'epoch': 6.98}\n",
            "{'loss': 2.3728, 'grad_norm': 1.4021120071411133, 'learning_rate': 9.133333333333335e-06, 'epoch': 6.99}\n",
            "{'loss': 2.3671, 'grad_norm': 1.3742996454238892, 'learning_rate': 8.577777777777778e-06, 'epoch': 7.0}\n",
            "{'loss': 2.3729, 'grad_norm': 1.481584906578064, 'learning_rate': 8.022222222222222e-06, 'epoch': 7.01}\n",
            "{'loss': 2.3497, 'grad_norm': 1.4625500440597534, 'learning_rate': 7.466666666666667e-06, 'epoch': 7.01}\n",
            "{'loss': 2.3429, 'grad_norm': 1.5621711015701294, 'learning_rate': 6.911111111111111e-06, 'epoch': 7.02}\n",
            "{'loss': 2.3203, 'grad_norm': 1.5668590068817139, 'learning_rate': 6.355555555555556e-06, 'epoch': 7.03}\n",
            "{'loss': 2.3449, 'grad_norm': 1.435674786567688, 'learning_rate': 5.7999999999999995e-06, 'epoch': 7.03}\n",
            "{'loss': 2.338, 'grad_norm': 1.5155515670776367, 'learning_rate': 5.244444444444445e-06, 'epoch': 7.04}\n",
            "{'loss': 2.3562, 'grad_norm': 1.4873297214508057, 'learning_rate': 4.6888888888888895e-06, 'epoch': 7.05}\n",
            "{'loss': 2.3456, 'grad_norm': 1.421289086341858, 'learning_rate': 4.133333333333333e-06, 'epoch': 7.06}\n",
            "{'loss': 2.3608, 'grad_norm': 1.648970365524292, 'learning_rate': 3.577777777777778e-06, 'epoch': 7.06}\n",
            "{'loss': 2.343, 'grad_norm': 1.4792840480804443, 'learning_rate': 3.022222222222222e-06, 'epoch': 7.07}\n",
            "{'loss': 2.3519, 'grad_norm': 1.3744730949401855, 'learning_rate': 2.4666666666666666e-06, 'epoch': 7.08}\n",
            "{'loss': 2.3329, 'grad_norm': 1.5394104719161987, 'learning_rate': 1.9111111111111112e-06, 'epoch': 7.08}\n",
            "{'loss': 2.3407, 'grad_norm': 1.5733658075332642, 'learning_rate': 1.3555555555555556e-06, 'epoch': 7.09}\n",
            "{'loss': 2.3395, 'grad_norm': 1.4566129446029663, 'learning_rate': 8.000000000000001e-07, 'epoch': 7.1}\n",
            "{'loss': 2.3528, 'grad_norm': 1.339188814163208, 'learning_rate': 2.4444444444444445e-07, 'epoch': 7.11}\n",
            "100% 50000/50000 [1:16:43<00:00, 11.06it/s]\n",
            "  0% 0/59 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 5/59 [00:00<00:01, 44.31it/s]\u001b[A\n",
            " 17% 10/59 [00:00<00:01, 43.42it/s]\u001b[A\n",
            " 25% 15/59 [00:00<00:01, 42.94it/s]\u001b[A\n",
            " 34% 20/59 [00:00<00:00, 42.99it/s]\u001b[A\n",
            " 42% 25/59 [00:00<00:01, 32.82it/s]\u001b[A\n",
            " 49% 29/59 [00:00<00:01, 26.63it/s]\u001b[A\n",
            " 54% 32/59 [00:01<00:01, 24.02it/s]\u001b[A\n",
            " 59% 35/59 [00:01<00:01, 22.25it/s]\u001b[A\n",
            " 64% 38/59 [00:01<00:01, 20.96it/s]\u001b[A\n",
            " 69% 41/59 [00:01<00:00, 20.15it/s]\u001b[A\n",
            " 75% 44/59 [00:01<00:00, 19.63it/s]\u001b[A\n",
            " 80% 47/59 [00:01<00:00, 19.19it/s]\u001b[A\n",
            " 83% 49/59 [00:01<00:00, 18.96it/s]\u001b[A\n",
            " 86% 51/59 [00:02<00:00, 18.86it/s]\u001b[A\n",
            " 90% 53/59 [00:02<00:00, 18.68it/s]\u001b[A\n",
            " 93% 55/59 [00:02<00:00, 18.59it/s]\u001b[A\n",
            " 97% 57/59 [00:02<00:00, 18.48it/s]\u001b[A\n",
            "                                           \n",
            "\u001b[A{'eval_loss': 2.3313746452331543, 'eval_accuracy': 0.5720511078834534, 'eval_runtime': 2.865, 'eval_samples_per_second': 1312.412, 'eval_steps_per_second': 20.594, 'epoch': 7.11}\n",
            "100% 50000/50000 [1:16:46<00:00, 11.06it/s]\n",
            "100% 59/59 [00:02<00:00, 17.72it/s]\u001b[A\n",
            "{'train_runtime': 4606.6957, 'train_samples_per_second': 2778.564, 'train_steps_per_second': 10.854, 'train_loss': 2.970574567260742, 'epoch': 7.11}\n",
            "100% 50000/50000 [1:16:46<00:00, 10.85it/s]\n",
            "100% 59/59 [00:02<00:00, 24.05it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   epoch â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval/accuracy â–â–ƒâ–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval/loss â–ˆâ–†â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/runtime â–ˆâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval/samples_per_second â–â–…â–…â–„â–…â–†â–†â–†â–„â–…â–…â–…â–„â–†â–†â–…â–†â–…â–†â–…â–„â–†â–„â–†â–…â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval/steps_per_second â–â–…â–…â–„â–…â–†â–†â–†â–„â–…â–…â–…â–„â–†â–†â–…â–†â–…â–†â–…â–„â–†â–„â–†â–…â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           eval_accuracy â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               eval_loss â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval_runtime â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: eval_samples_per_second â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   eval_steps_per_second â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/grad_norm â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train/learning_rate â–‚â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/loss â–ˆâ–ˆâ–†â–†â–†â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    epoch 7.1053\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval/accuracy 0.56645\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval/loss 2.35388\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval/runtime 2.7597\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  eval/samples_per_second 1362.484\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval/steps_per_second 21.379\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            eval_accuracy 0.56645\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                eval_loss 2.35388\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             eval_runtime 2.7597\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  eval_samples_per_second 1362.484\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    eval_steps_per_second 21.379\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               total_flos 6.200948602935706e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/epoch 7.1053\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train/global_step 50000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          train/grad_norm 1.33919\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/loss 2.3528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train_loss 2.97057\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_runtime 4606.6957\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_samples_per_second 2778.564\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train_steps_per_second 10.854\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33m13.47M - rd.32 - 6.mha - mlp.1024 - model.256.lyr.6 - ah.8.32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/chrismccormick/encoder-pretrain-wiki103/runs/v5b5e3gh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/chrismccormick/encoder-pretrain-wiki103\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250808_152951-v5b5e3gh/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n======= Pre-Train ========\\n\")\n",
        "\n",
        "# Construct the command line\n",
        "train_command = (\n",
        "    f\"PYTHONPATH={base_path} \"\n",
        "    f\"WANDB_MODE={wandb_mode} \"\n",
        "    f'WANDB_API_KEY=\"{wandb_key}\" '\n",
        "    f\"python {base_path}/scripts/train.py --config {pretrain_config_path}\"\n",
        ")\n",
        "\n",
        "# Run pre-training\n",
        "!{train_command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHVezQcela9q"
      },
      "source": [
        "**Optional - Save the checkpoint to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3eW0xow4lc1h",
        "outputId": "0e5b8a2e-9015-4379-de94-70ac36e404e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/encoder-pretrain-wiki103/checkpoints'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "if False:\n",
        "    # Copy whatever's in the checkpoints folder over to Google Drive.\n",
        "    shutil.copytree(\n",
        "        \"/content/checkpoints\",\n",
        "        \"/content/drive/MyDrive/decoder-pretrain-wiki103/checkpoints\",\n",
        "        dirs_exist_ok = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPfIYtJUhU6M"
      },
      "source": [
        "# â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SagN8mgICj-g"
      },
      "source": [
        "# Defining a New Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QHYgedWDcd5"
      },
      "source": [
        "To modify the parameters from the command line, I created a command line utiltity in `/configs/create_new_config.py` which will copy one of the existing config files and allow you to specify any parameter changes.\n",
        "\n",
        "See the [script](https://github.com/chrisjmccormick/shared-subspaces/blob/main/subspace_encoder/configs/create_new_config.py) for documentation, check out the baseline config [here](https://github.com/chrisjmccormick/shared-subspaces/blob/main/subspace_encoder/configs/best_mla-o.json) to see all of the hyperparameters that are defined, and see the [Config](https://github.com/chrisjmccormick/shared-subspaces/blob/main/subspace_encoder/models/shared_space_config.py#L81) class for documentation of the model parameters.\n",
        "\n",
        "Below is an example for defining a new run which increases the output latent size to 96."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY-fQBEYeQ69",
        "outputId": "e567a46f-9dee-4777-e512-650d14bd118c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote new config to /content/shared-subspaces/subspace_encoder/configs/mla-o_baseline_o96.json\n"
          ]
        }
      ],
      "source": [
        "!python {base_path}/configs/create_new_config.py \\\n",
        "    mla-o_baseline_o96\n",
        "    --base {base_path}/configs/mla-o_baseline.json \\\n",
        "    --shorthand \"rd.32 - 6.mla.64.32.96 - mlp.1024 - model.256.lyr.6 - ah.8.32\" \\\n",
        "    --notes \"Trying increasing the output subspace size from 64 to 96\" \\\n",
        "    --set model.o_latent_dim=96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGuGV59klfBM",
        "outputId": "228bd8a5-78ef-45e2-81f1-7651141fb3a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"shorthand\": \"rd.32 - 6.mla.64.32.96 - mlp.1024 - model.256.lyr.6 - ah.8.32\",\n",
            "  \"notes\": \"Trying increasing the output subspace size from 64 to 96\",\n",
            "  \"model\": {\n",
            "    \"hidden_size\": 256,\n",
            "    \"num_hidden_layers\": 6,\n",
            "    \"intermediate_size\": 1024,\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"attention_dropout_prob\": 0.1,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"rms_norm_eps\": 1e-06,\n",
            "    \"vocab_size\": 30522,\n",
            "    \"rope_theta\": 10000.0,\n",
            "    \"rope_scaling\": null,\n",
            "    \"max_position_embeddings\": 128,\n",
            "    \"num_dense_layers\": 0,\n",
            "    \"q_latent_dim\": 64,\n",
            "    \"kv_latent_dim\": 32,\n",
            "    \"num_attention_heads\": 8,\n",
            "    \"head_dim\": 32,\n",
            "    \"rope_dims\": 32,\n",
            "    \"attention_bias\": false,\n",
            "    \"output_subspace\": true,\n",
            "    \"o_latent_dim\": 96,\n",
            "    \"attention_backend\": \"sdpa\",\n",
            "    \"ffn_decompose\": false,\n",
            "    \"ffn_rank\": null,\n",
            "    \"vocab_subspace\": false,\n",
            "    \"vocab_rank\": 128\n",
            "  },\n",
            "  \"pre_train\": {\n",
            "    \"output_dir\": \"checkpoints/mla-o_baseline_o96\",\n",
            "    \"seed\": 42,\n",
            "    \"train_batch_size\": 256,\n",
            "    \"learning_rate\": 0.0005,\n",
            "    \"num_train_steps\": 50000,\n",
            "    \"eval_steps\": 2000,\n",
            "    \"weight_decay\": 0.01,\n",
            "    \"mlm_probability\": 0.15,\n",
            "    \"dataset_name\": \"wikitext\",\n",
            "    \"dataset_config\": \"wikitext-103-raw-v1\",\n",
            "    \"max_seq_length\": 128,\n",
            "    \"eval_batch_size\": 64,\n",
            "    \"fp16\": true\n",
            "  },\n",
            "  \"fine_tune\": {\n",
            "    \"task\": \"sst2\",\n",
            "    \"batch_size\": 16,\n",
            "    \"lr\": 2e-05,\n",
            "    \"epochs\": 3,\n",
            "    \"seed\": 42,\n",
            "    \"max_length\": 128\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "!cat {base_path}/configs/mla-o_baseline_o96.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3uaKyPGMiXW"
      },
      "source": [
        "# â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
