{
    "shorthand": "rd.16 - 6.mla.64.32 - mlp.1024 - model.256.lyr.6 - ah.8.32",
    
    "notes": "Initial MLA configuration",
    
    "model": {
        
      "hidden_size":              256,
  
      "num_hidden_layers":        6,
      "num_nextn_predict_layers": 1,
  
      "moe_intermediate_size": 128,
      "intermediate_size":     1024,
      "n_shared_experts":      1,
      "n_routed_experts":      4,
      "ep_size":               1,
      "routed_scaling_factor": 1,
      "num_experts_per_tok":   2,
      "moe_layer_freq":        2,
      "first_k_dense_replace": 1,
      "topk_method":           "softmax_aux",
      "n_group":               1,
      "topk_group":            1,
      "norm_topk_prob":        true,
      "scoring_func":          "softmax",
      "hidden_act":            "silu",
  
      "use_cache":             false,
      "pad_token_id":          null,
      "bos_token_id":          0,
      "eos_token_id":          1,
      "tie_word_embeddings":   true,
      "attention_dropout":     0.0,
      
      "hidden_dropout_prob":    0.1,
      "attention_dropout_prob": 0.1,
      "classifier_dropout":     null,
          
      "initializer_range":    0.02,
      "rms_norm_eps":         1e-6,
  
      "vocab_size":           128000,
      "rope_theta":           10000.0,
      "rope_scaling":         null,
      "max_position_embeddings":  128,
  
      "kv_lora_rank":         32,
      "q_lora_rank":          64,
      "qk_rope_head_dim":     32,
      "v_head_dim":           32,
      "qk_nope_head_dim":     0,
  
      "num_attention_heads":  8,
      "num_key_value_heads":  8,
      "attention_bias":       false,	
      
      "use_output_subspace": true,
      "o_latent_dim":        64,
      
      "attention_backend": "eager"
  
    },
    
    "pre_train": {
      "output_dir":        "checkpoints/initial_mla",
      "seed":              42,
      
      "train_batch_size":  128,
      "learning_rate":     5e-4,
      "num_train_steps":   50000,
      "eval_steps":        2000,
      "weight_decay":      0.01,
      
      "num_workers":       8,
      "pin_memory":        true,
      
      "dataset_name":      "wikitext",
      "dataset_config":    "wikitext-103-raw-v1",
      
      "max_seq_length":    128,
      "eval_batch_size":   32,
      
      "fp16":              true
    }
}
  